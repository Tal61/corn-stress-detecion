from __future__ import print_function, division

Wavelength = [
    395.68,
    396.37,
    397.06,
    397.76,
    398.45,
    399.14,
    399.84,
    400.53,
    401.22,
    401.92,
    402.61,
    403.31,
    404.00,
    404.69,
    405.39,
    406.08,
    406.78,
    407.47,
    408.17,
    408.86,
    409.55,
    410.25,
    410.94,
    411.64,
    412.33,
    413.03,
    413.72,
    414.42,
    415.11,
    415.81,
    416.50,
    417.20,
    417.90,
    418.59,
    419.29,
    419.98,
    420.68,
    421.37,
    422.07,
    422.77,
    423.46,
    424.16,
    424.85,
    425.55,
    426.25,
    426.94,
    427.64,
    428.34,
    429.03,
    429.73,
    430.43,
    431.13,
    431.82,
    432.52,
    433.22,
    433.91,
    434.61,
    435.31,
    436.01,
    436.70,
    437.40,
    438.10,
    438.80,
    439.50,
    440.19,
    440.89,
    441.59,
    442.29,
    442.99,
    443.69,
    444.39,
    445.08,
    445.78,
    446.48,
    447.18,
    447.88,
    448.58,
    449.28,
    449.98,
    450.68,
    451.38,
    452.08,
    452.77,
    453.47,
    454.17,
    454.87,
    455.57,
    456.27,
    456.97,
    457.67,
    458.37,
    459.07,
    459.77,
    460.48,
    461.18,
    461.88,
    462.58,
    463.28,
    463.98,
    464.68,
    465.38,
    466.08,
    466.78,
    467.48,
    468.19,
    468.89,
    469.59,
    470.29,
    470.99,
    471.69,
    472.40,
    473.10,
    473.80,
    474.50,
    475.20,
    475.91,
    476.61,
    477.31,
    478.01,
    478.72,
    479.42,
    480.12,
    480.82,
    481.53,
    482.23,
    482.93,
    483.64,
    484.34,
    485.04,
    485.75,
    486.45,
    487.15,
    487.86,
    488.56,
    489.26,
    489.97,
    490.67,
    491.38,
    492.08,
    492.78,
    493.49,
    494.19,
    494.90,
    495.60,
    496.31,
    497.01,
    497.72,
    498.42,
    499.12,
    499.83,
    500.53,
    501.24,
    501.95,
    502.65,
    503.36,
    504.06,
    504.77,
    505.47,
    506.18,
    506.88,
    507.59,
    508.30,
    509.00,
    509.71,
    510.41,
    511.12,
    511.83,
    512.53,
    513.24,
    513.95,
    514.65,
    515.36,
    516.07,
    516.77,
    517.48,
    518.19,
    518.90,
    519.60,
    520.31,
    521.02,
    521.72,
    522.43,
    523.14,
    523.85,
    524.56,
    525.26,
    525.97,
    526.68,
    527.39,
    528.10,
    528.80,
    529.51,
    530.22,
    530.93,
    531.64,
    532.35,
    533.06,
    533.76,
    534.47,
    535.18,
    535.89,
    536.60,
    537.31,
    538.02,
    538.73,
    539.44,
    540.15,
    540.86,
    541.57,
    542.28,
    542.99,
    543.70,
    544.41,
    545.12,
    545.83,
    546.54,
    547.25,
    547.96,
    548.67,
    549.38,
    550.09,
    550.80,
    551.51,
    552.22,
    552.93,
    553.65,
    554.36,
    555.07,
    555.78,
    556.49,
    557.20,
    557.91,
    558.63,
    559.34,
    560.05,
    560.76,
    561.47,
    562.19,
    562.90,
    563.61,
    564.32,
    565.03,
    565.75,
    566.46,
    567.17,
    567.89,
    568.60,
    569.31,
    570.02,
    570.74,
    571.45,
    572.16,
    572.88,
    573.59,
    574.30,
    575.02,
    575.73,
    576.44,
    577.16,
    577.87,
    578.59,
    579.30,
    580.01,
    580.73,
    581.44,
    582.16,
    582.87,
    583.59,
    584.30,
    585.02,
    585.73,
    586.45,
    587.16,
    587.88,
    588.59,
    589.31,
    590.02,
    590.74,
    591.45,
    592.17,
    592.88,
    593.60,
    594.31,
    595.03,
    595.75,
    596.46,
    597.18,
    597.89,
    598.61,
    599.33,
    600.04,
    600.76,
    601.48,
    602.19,
    602.91,
    603.63,
    604.34,
    605.06,
    605.78,
    606.49,
    607.21,
    607.93,
    608.65,
    609.36,
    610.08,
    610.80,
    611.52,
    612.23,
    612.95,
    613.67,
    614.39,
    615.11,
    615.82,
    616.54,
    617.26,
    617.98,
    618.70,
    619.42,
    620.13,
    620.85,
    621.57,
    622.29,
    623.01,
    623.73,
    624.45,
    625.17,
    625.89,
    626.61,
    627.33,
    628.05,
    628.76,
    629.48,
    630.20,
    630.92,
    631.64,
    632.36,
    633.08,
    633.80,
    634.52,
    635.24,
    635.97,
    636.69,
    637.41,
    638.13,
    638.85,
    639.57,
    640.29,
    641.01,
    641.73,
    642.45,
    643.17,
    643.90,
    644.62,
    645.34,
    646.06,
    646.78,
    647.50,
    648.23,
    648.95,
    649.67,
    650.39,
    651.11,
    651.84,
    652.56,
    653.28,
    654.00,
    654.72,
    655.45,
    656.17,
    656.89,
    657.62,
    658.34,
    659.06,
    659.79,
    660.51,
    661.23,
    661.95,
    662.68,
    663.40,
    664.13,
    664.85,
    665.57,
    666.30,
    667.02,
    667.74,
    668.47,
    669.19,
    669.92,
    670.64,
    671.37,
    672.09,
    672.81,
    673.54,
    674.26,
    674.99,
    675.71,
    676.44,
    677.16,
    677.89,
    678.61,
    679.34,
    680.06,
    680.79,
    681.52,
    682.24,
    682.97,
    683.69,
    684.42,
    685.14,
    685.87,
    686.60,
    687.32,
    688.05,
    688.78,
    689.50,
    690.23,
    690.95,
    691.68,
    692.41,
    693.14,
    693.86,
    694.59,
    695.32,
    696.04,
    696.77,
    697.50,
    698.23,
    698.95,
    699.68,
    700.41,
    701.14,
    701.86,
    702.59,
    703.32,
    704.05,
    704.78,
    705.50,
    706.23,
    706.96,
    707.69,
    708.42,
    709.15,
    709.87,
    710.60,
    711.33,
    712.06,
    712.79,
    713.52,
    714.25,
    714.98,
    715.71,
    716.44,
    717.17,
    717.90,
    718.62,
    719.35,
    720.08,
    720.81,
    721.54,
    722.27,
    723.00,
    723.73,
    724.47,
    725.20,
    725.93,
    726.66,
    727.39,
    728.12,
    728.85,
    729.58,
    730.31,
    731.04,
    731.77,
    732.50,
    733.23,
    733.97,
    734.70,
    735.43,
    736.16,
    736.89,
    737.62,
    738.36,
    739.09,
    739.82,
    740.55,
    741.28,
    742.02,
    742.75,
    743.48,
    744.21,
    744.95,
    745.68,
    746.41,
    747.14,
    747.88,
    748.61,
    749.34,
    750.08,
    750.81,
    751.54,
    752.28,
    753.01,
    753.74,
    754.48,
    755.21,
    755.94,
    756.68,
    757.41,
    758.15,
    758.88,
    759.61,
    760.35,
    761.08,
    761.82,
    762.55,
    763.29,
    764.02,
    764.76,
    765.49,
    766.23,
    766.96,
    767.70,
    768.43,
    769.17,
    769.90,
    770.64,
    771.37,
    772.11,
    772.84,
    773.58,
    774.32,
    775.05,
    775.79,
    776.52,
    777.26,
    778.00,
    778.73,
    779.47,
    780.20,
    780.94,
    781.68,
    782.41,
    783.15,
    783.89,
    784.62,
    785.36,
    786.10,
    786.84,
    787.57,
    788.31,
    789.05,
    789.79,
    790.52,
    791.26,
    792.00,
    792.74,
    793.47,
    794.21,
    794.95,
    795.69,
    796.43,
    797.17,
    797.90,
    798.64,
    799.38,
    800.12,
    800.86,
    801.60,
    802.34,
    803.07,
    803.81,
    804.55,
    805.29,
    806.03,
    806.77,
    807.51,
    808.25,
    808.99,
    809.73,
    810.47,
    811.21,
    811.95,
    812.69,
    813.43,
    814.17,
    814.91,
    815.65,
    816.39,
    817.13,
    817.87,
    818.61,
    819.35,
    820.09,
    820.83,
    821.57,
    822.32,
    823.06,
    823.80,
    824.54,
    825.28,
    826.02,
    826.76,
    827.51,
    828.25,
    828.99,
    829.73,
    830.47,
    831.21,
    831.96,
    832.70,
    833.44,
    834.18,
    834.93,
    835.67,
    836.41,
    837.15,
    837.90,
    838.64,
    839.38,
    840.13,
    840.87,
    841.61,
    842.35,
    843.10,
    843.84,
    844.58,
    845.33,
    846.07,
    846.82,
    847.56,
    848.30,
    849.05,
    849.79,
    850.54,
    851.28,
    852.02,
    852.77,
    853.51,
    854.26,
    855.00,
    855.75,
    856.49,
    857.24,
    857.98,
    858.73,
    859.47,
    860.22,
    860.96,
    861.71,
    862.45,
    863.20,
    863.94,
    864.69,
    865.44,
    866.18,
    866.93,
    867.67,
    868.42,
    869.17,
    869.91,
    870.66,
    871.40,
    872.15,
    872.90,
    873.64,
    874.39,
    875.14,
    875.88,
    876.63,
    877.38,
    878.13,
    878.87,
    879.62,
    880.37,
    881.11,
    881.86,
    882.61,
    883.36,
    884.11,
    884.85,
    885.60,
    886.35,
    887.10,
    887.85,
    888.59,
    889.34,
    890.09,
    890.84,
    891.59,
    892.34,
    893.08,
    893.83,
    894.58,
    895.33,
    896.08,
    896.83,
    897.58,
    898.33,
    899.08,
    899.83,
    900.58,
    901.33,
    902.08,
    902.83,
    903.58,
    904.33,
    905.08,
    905.83,
    906.58,
    907.33,
    908.08,
    908.83,
    909.58,
    910.33,
    911.08,
    911.83,
    912.58,
    913.33,
    914.08,
    914.83,
    915.58,
    916.34,
    917.09,
    917.84,
    918.59,
    919.34,
    920.09,
    920.85,
    921.60,
    922.35,
    923.10,
    923.85,
    924.60,
    925.36,
    926.11,
    926.86,
    927.61,
    928.37,
    929.12,
    929.87,
    930.62,
    931.38,
    932.13,
    932.88,
    933.64,
    934.39,
    935.14,
    935.90,
    936.65,
    937.40,
    938.16,
    938.91,
    939.66,
    940.42,
    941.17,
    941.93,
    942.68,
    943.43,
    944.19,
    944.94,
    945.70,
    946.45,
    947.21,
    947.96,
    948.72,
    949.47,
    950.23,
    950.98,
    951.74,
    952.49,
    953.25,
    954.00,
    954.76,
    955.51,
    956.27,
    957.02,
    957.78,
    958.53,
    959.29,
    960.05,
    960.80,
    961.56,
    962.31,
    963.07,
    963.83,
    964.58,
    965.34,
    966.10,
    966.85,
    967.61,
    968.37,
    969.12,
    969.88,
    970.64,
    971.40,
    972.15,
    972.91,
    973.67,
    974.42,
    975.18,
    975.94,
    976.70,
    977.46,
    978.21,
    978.97,
    979.73,
    980.49,
    981.25,
    982.00,
    982.76,
    983.52,
    984.28,
    985.04,
    985.80,
    986.56,
    987.31,
    988.07,
    988.83,
    989.59,
    990.35,
    991.11,
    991.87,
    992.63,
    993.39,
    994.15,
    994.91,
    995.67,
    996.43,
    997.19,
    997.95,
    998.71,
    999.47,
    1000.23,
    1000.99,
    1001.75,
    1002.51,
    1003.27,
    1004.03,
    1004.79,
    1005.55
]

channel_means = [0.0156, 0.0196, 0.0201, 0.0199, 0.0217, 0.0212, 0.0225, 0.0235, 0.0238,
                 0.0252, 0.0265, 0.0270, 0.0273, 0.0273, 0.0296, 0.0307, 0.0310, 0.0309,
                 0.0318, 0.0312, 0.0323, 0.0310, 0.0328, 0.0345, 0.0341, 0.0350, 0.0359,
                 0.0355, 0.0344, 0.0366, 0.0344, 0.0358, 0.0404, 0.0373, 0.0373, 0.0367,
                 0.0377, 0.0406, 0.0411, 0.0376, 0.0376, 0.0367, 0.0380, 0.0374, 0.0400,
                 0.0386, 0.0388, 0.0377, 0.0388, 0.0387, 0.0362, 0.0361, 0.0355, 0.0377,
                 0.0365, 0.0383, 0.0371, 0.0394, 0.0399, 0.0367, 0.0388, 0.0370, 0.0371,
                 0.0380, 0.0393, 0.0389, 0.0396, 0.0395, 0.0391, 0.0377, 0.0391, 0.0377,
                 0.0364, 0.0406, 0.0408, 0.0385, 0.0420, 0.0394, 0.0398, 0.0405, 0.0388,
                 0.0406, 0.0395, 0.0380, 0.0401, 0.0377, 0.0408, 0.0418, 0.0409, 0.0364,
                 0.0415, 0.0405, 0.0375, 0.0397, 0.0401, 0.0390, 0.0374, 0.0421, 0.0410,
                 0.0386, 0.0382, 0.0392, 0.0404, 0.0378, 0.0403, 0.0399, 0.0405, 0.0379,
                 0.0382, 0.0421, 0.0369, 0.0372, 0.0400, 0.0385, 0.0409, 0.0427, 0.0390,
                 0.0377, 0.0401, 0.0418, 0.0415, 0.0361, 0.0375, 0.0402, 0.0391, 0.0400,
                 0.0424, 0.0387, 0.0382, 0.0367, 0.0381, 0.0401, 0.0426, 0.0379, 0.0389,
                 0.0412, 0.0387, 0.0402, 0.0376, 0.0398, 0.0401, 0.0387, 0.0393, 0.0387,
                 0.0386, 0.0436, 0.0394, 0.0376, 0.0392, 0.0377, 0.0422, 0.0394, 0.0384,
                 0.0409, 0.0419, 0.0422, 0.0390, 0.0419, 0.0408, 0.0411, 0.0408, 0.0434,
                 0.0400, 0.0415, 0.0410, 0.0408, 0.0426, 0.0443, 0.0426, 0.0449, 0.0461,
                 0.0416, 0.0468, 0.0495, 0.0453, 0.0451, 0.0464, 0.0444, 0.0466, 0.0459,
                 0.0462, 0.0487, 0.0442, 0.0495, 0.0491, 0.0471, 0.0496, 0.0484, 0.0475,
                 0.0492, 0.0508, 0.0539, 0.0491, 0.0546, 0.0531, 0.0508, 0.0553, 0.0546,
                 0.0530, 0.0526, 0.0523, 0.0547, 0.0506, 0.0529, 0.0523, 0.0556, 0.0540,
                 0.0521, 0.0522, 0.0514, 0.0555, 0.0553, 0.0540, 0.0535, 0.0548, 0.0532,
                 0.0524, 0.0538, 0.0555, 0.0538, 0.0557, 0.0541, 0.0543, 0.0530, 0.0566,
                 0.0553, 0.0562, 0.0563, 0.0548, 0.0563, 0.0546, 0.0575, 0.0551, 0.0525,
                 0.0565, 0.0573, 0.0537, 0.0524, 0.0559, 0.0539, 0.0596, 0.0529, 0.0565,
                 0.0520, 0.0551, 0.0555, 0.0540, 0.0523, 0.0537, 0.0531, 0.0525, 0.0530,
                 0.0549, 0.0528, 0.0479, 0.0533, 0.0530, 0.0510, 0.0502, 0.0501, 0.0514,
                 0.0507, 0.0475, 0.0516, 0.0488, 0.0506, 0.0503, 0.0486, 0.0513, 0.0523,
                 0.0520, 0.0474, 0.0491, 0.0489, 0.0480, 0.0469, 0.0477, 0.0482, 0.0495,
                 0.0488, 0.0485, 0.0510, 0.0493, 0.0481, 0.0459, 0.0496, 0.0503, 0.0498,
                 0.0479, 0.0497, 0.0486, 0.0467, 0.0461, 0.0486, 0.0477, 0.0483, 0.0496,
                 0.0488, 0.0516, 0.0458, 0.0477, 0.0493, 0.0462, 0.0482, 0.0469, 0.0448,
                 0.0478, 0.0501, 0.0445, 0.0468, 0.0454, 0.0485, 0.0463, 0.0456, 0.0459,
                 0.0468, 0.0478, 0.0465, 0.0439, 0.0455, 0.0461, 0.0446, 0.0435, 0.0441,
                 0.0455, 0.0455, 0.0446, 0.0453, 0.0446, 0.0454, 0.0430, 0.0470, 0.0458,
                 0.0461, 0.0454, 0.0444, 0.0431, 0.0459, 0.0456, 0.0458, 0.0461, 0.0456,
                 0.0447, 0.0458, 0.0457, 0.0454, 0.0474, 0.0451, 0.0445, 0.0421, 0.0441,
                 0.0430, 0.0426, 0.0412, 0.0446, 0.0422, 0.0426, 0.0450, 0.0442, 0.0418,
                 0.0399, 0.0438, 0.0430, 0.0414, 0.0454, 0.0430, 0.0434, 0.0424, 0.0417,
                 0.0428, 0.0394, 0.0434, 0.0391, 0.0406, 0.0396, 0.0436, 0.0438, 0.0397,
                 0.0420, 0.0422, 0.0436, 0.0423, 0.0401, 0.0403, 0.0363, 0.0399, 0.0394,
                 0.0385, 0.0428, 0.0376, 0.0416, 0.0362, 0.0397, 0.0409, 0.0383, 0.0405,
                 0.0430, 0.0382, 0.0403, 0.0400, 0.0365, 0.0387, 0.0395, 0.0397, 0.0399,
                 0.0407, 0.0434, 0.0415, 0.0409, 0.0393, 0.0401, 0.0375, 0.0411, 0.0405,
                 0.0411, 0.0447, 0.0441, 0.0449, 0.0457, 0.0452, 0.0467, 0.0478, 0.0501,
                 0.0507, 0.0516, 0.0535, 0.0540, 0.0510, 0.0535, 0.0570, 0.0577, 0.0592,
                 0.0596, 0.0592, 0.0608, 0.0633, 0.0612, 0.0641, 0.0641, 0.0674, 0.0664,
                 0.0657, 0.0703, 0.0663, 0.0669, 0.0682, 0.0711, 0.0742, 0.0718, 0.0728,
                 0.0731, 0.0744, 0.0716, 0.0753, 0.0746, 0.0751, 0.0777, 0.0797, 0.0787,
                 0.0790, 0.0801, 0.0802, 0.0792, 0.0834, 0.0787, 0.0802, 0.0850, 0.0830,
                 0.0840, 0.0804, 0.0856, 0.0874, 0.0895, 0.0904, 0.0885, 0.0903, 0.0904,
                 0.0881, 0.0880, 0.0871, 0.0905, 0.0897, 0.0920, 0.0902, 0.0938, 0.0912,
                 0.0914, 0.0932, 0.0917, 0.0932, 0.0909, 0.0890, 0.0965, 0.0949, 0.0934,
                 0.0961, 0.0921, 0.0959, 0.0969, 0.0906, 0.0919, 0.0929, 0.0937, 0.0964,
                 0.0954, 0.0956, 0.0934, 0.0932, 0.0932, 0.0897, 0.0850, 0.0830, 0.0919,
                 0.0939, 0.0907, 0.0874, 0.0903, 0.0975, 0.0915, 0.0941, 0.0946, 0.0973,
                 0.0954, 0.0942, 0.0947, 0.0920, 0.0910, 0.0925, 0.0934, 0.0952, 0.0944,
                 0.0955, 0.0912, 0.0936, 0.0907, 0.0917, 0.0939, 0.0931, 0.0936, 0.0949,
                 0.0914, 0.0939, 0.0939, 0.0957, 0.0932, 0.0923, 0.0901, 0.0964, 0.0927,
                 0.0895, 0.0965, 0.0976, 0.0954, 0.0917, 0.0940, 0.0942, 0.0991, 0.0899,
                 0.0916, 0.0920, 0.0926, 0.0946, 0.0932, 0.0943, 0.0926, 0.0960, 0.0923,
                 0.0914, 0.0923, 0.0910, 0.0937, 0.0951, 0.0945, 0.0933, 0.0951, 0.0965,
                 0.0922, 0.0933, 0.0941, 0.0935, 0.0911, 0.0940, 0.0910, 0.0905, 0.0909,
                 0.0911, 0.0897, 0.0898, 0.0908, 0.0913, 0.0916, 0.0952, 0.0900, 0.0890,
                 0.0947, 0.0904, 0.0927, 0.0922, 0.0925, 0.0908, 0.0912, 0.0929, 0.0928,
                 0.0896, 0.0919, 0.0923, 0.0910, 0.0922, 0.0943, 0.0933, 0.0909, 0.0901,
                 0.0914, 0.0930, 0.0914, 0.0882, 0.0946, 0.0903, 0.0995, 0.0936, 0.0948,
                 0.0926, 0.0931, 0.0931, 0.0992, 0.0935, 0.0929, 0.0905, 0.0928, 0.0913,
                 0.0917, 0.0914, 0.0910, 0.0881, 0.0902, 0.0913, 0.0889, 0.0927, 0.0925,
                 0.0963, 0.0942, 0.0930, 0.0886, 0.0938, 0.0885, 0.0946, 0.0902, 0.0894,
                 0.0887, 0.0897, 0.0910, 0.0936, 0.0914, 0.0899, 0.0906, 0.0932, 0.0926,
                 0.0944, 0.0903, 0.0926, 0.0911, 0.0908, 0.0916, 0.0944, 0.0904, 0.0919,
                 0.0892, 0.0911, 0.0932, 0.0899, 0.0904, 0.0910, 0.0899, 0.0924, 0.0875,
                 0.0890, 0.0917, 0.0909, 0.0875, 0.0906, 0.0907, 0.0903, 0.0945, 0.0912,
                 0.0903, 0.0890, 0.0887, 0.0927, 0.0932, 0.0905, 0.0923, 0.0921, 0.0903,
                 0.0890, 0.0863, 0.0850, 0.0877, 0.0884, 0.0890, 0.0845, 0.0840, 0.0822,
                 0.0872, 0.0856, 0.0863, 0.0872, 0.0828, 0.0819, 0.0800, 0.0791, 0.0797,
                 0.0791, 0.0819, 0.0831, 0.0842, 0.0809, 0.0816, 0.0814, 0.0823, 0.0813,
                 0.0805, 0.0792, 0.0815, 0.0841, 0.0817, 0.0864, 0.0845, 0.0823, 0.0824,
                 0.0839]

channel_std = [5.7648e-02, 6.0769e-02, 5.9244e-02, 5.3018e-02, 5.9318e-02, 5.5226e-02,
               5.5884e-02, 6.0756e-02, 5.6206e-02, 5.6256e-02, 5.6149e-02, 6.0581e-02,
               5.8924e-02, 6.0285e-02, 6.6594e-02, 6.3907e-02, 6.5910e-02, 6.7677e-02,
               6.8400e-02, 6.7577e-02, 6.7731e-02, 7.0451e-02, 7.1152e-02, 7.0675e-02,
               7.2403e-02, 7.7440e-02, 7.3617e-02, 7.6467e-02, 7.4637e-02, 8.2258e-02,
               7.8171e-02, 8.0076e-02, 8.0023e-02, 8.1349e-02, 8.0214e-02, 8.1480e-02,
               8.0133e-02, 8.1567e-02, 8.4270e-02, 8.6018e-02, 8.0375e-02, 7.9312e-02,
               8.3728e-02, 8.3366e-02, 8.6766e-02, 8.6460e-02, 8.1136e-02, 8.6204e-02,
               8.1134e-02, 8.4576e-02, 8.5625e-02, 8.5011e-02, 8.2267e-02, 8.7295e-02,
               8.4312e-02, 8.3199e-02, 8.6400e-02, 8.4897e-02, 8.5557e-02, 8.4678e-02,
               8.5248e-02, 8.4925e-02, 8.4570e-02, 8.4508e-02, 8.4109e-02, 8.7159e-02,
               8.8151e-02, 8.5581e-02, 8.2493e-02, 8.1533e-02, 8.3121e-02, 8.4062e-02,
               8.2539e-02, 8.4460e-02, 8.4236e-02, 8.7648e-02, 8.4219e-02, 8.6790e-02,
               8.0522e-02, 8.5998e-02, 8.3715e-02, 8.6442e-02, 8.7443e-02, 8.3965e-02,
               8.3995e-02, 8.4255e-02, 8.4860e-02, 8.2051e-02, 8.5692e-02, 8.1866e-02,
               8.6679e-02, 8.5398e-02, 8.3352e-02, 8.5592e-02, 8.4450e-02, 8.4768e-02,
               8.3526e-02, 8.5245e-02, 8.1510e-02, 8.1745e-02, 8.3337e-02, 8.6151e-02,
               8.4425e-02, 8.1879e-02, 8.4252e-02, 8.2593e-02, 8.4503e-02, 8.4324e-02,
               8.2439e-02, 8.1411e-02, 8.4935e-02, 8.5077e-02, 7.8528e-02, 8.4904e-02,
               8.3895e-02, 8.1788e-02, 8.3373e-02, 8.2313e-02, 8.1785e-02, 8.2144e-02,
               8.0516e-02, 7.9152e-02, 8.3685e-02, 8.5408e-02, 8.1844e-02, 8.2859e-02,
               8.6296e-02, 8.1443e-02, 8.3189e-02, 8.1235e-02, 8.0873e-02, 8.2869e-02,
               8.4817e-02, 8.0835e-02, 8.4402e-02, 8.6397e-02, 8.5927e-02, 8.1986e-02,
               8.1874e-02, 8.5217e-02, 8.1800e-02, 8.4203e-02, 8.4821e-02, 8.0463e-02,
               8.5288e-02, 8.2253e-02, 8.0628e-02, 8.0605e-02, 8.4036e-02, 8.2557e-02,
               8.1460e-02, 8.4007e-02, 8.2737e-02, 8.4551e-02, 8.3610e-02, 8.4701e-02,
               8.2434e-02, 7.8531e-02, 8.4640e-02, 8.3116e-02, 8.5364e-02, 8.4168e-02,
               8.4077e-02, 8.3722e-02, 8.3771e-02, 8.7242e-02, 8.6652e-02, 8.6951e-02,
               8.7008e-02, 8.5959e-02, 8.7208e-02, 8.7431e-02, 8.6989e-02, 8.9109e-02,
               8.6300e-02, 8.9576e-02, 9.2387e-02, 8.9517e-02, 8.9374e-02, 9.3362e-02,
               8.7970e-02, 9.3135e-02, 9.1941e-02, 9.5341e-02, 9.4545e-02, 9.6527e-02,
               9.8060e-02, 9.5458e-02, 9.4570e-02, 9.8566e-02, 9.8714e-02, 9.8966e-02,
               9.9146e-02, 1.0074e-01, 1.0400e-01, 9.9594e-02, 1.0267e-01, 1.0009e-01,
               1.0319e-01, 1.0252e-01, 1.0101e-01, 1.0522e-01, 1.0147e-01, 1.0479e-01,
               1.0349e-01, 1.0411e-01, 1.0186e-01, 1.0402e-01, 1.0427e-01, 1.0256e-01,
               1.0568e-01, 1.0422e-01, 1.0461e-01, 1.0443e-01, 1.0350e-01, 1.0345e-01,
               1.0341e-01, 1.0736e-01, 1.0646e-01, 1.0602e-01, 1.0518e-01, 1.0507e-01,
               1.0645e-01, 1.0574e-01, 1.0418e-01, 1.0738e-01, 1.0635e-01, 1.0315e-01,
               1.0811e-01, 1.0613e-01, 1.0410e-01, 1.0635e-01, 1.0630e-01, 1.0485e-01,
               1.0602e-01, 1.0443e-01, 1.0004e-01, 1.0178e-01, 1.0655e-01, 1.0480e-01,
               1.0377e-01, 1.0264e-01, 1.0579e-01, 1.0142e-01, 1.0455e-01, 1.0345e-01,
               1.0271e-01, 1.0167e-01, 9.9891e-02, 1.0050e-01, 1.0000e-01, 1.0045e-01,
               9.8960e-02, 9.9021e-02, 9.6398e-02, 9.5203e-02, 9.5481e-02, 9.4787e-02,
               9.4542e-02, 9.4608e-02, 9.5507e-02, 9.7368e-02, 9.3656e-02, 9.8184e-02,
               9.4789e-02, 9.3174e-02, 9.3662e-02, 9.3386e-02, 9.2022e-02, 9.4925e-02,
               9.4444e-02, 9.2238e-02, 9.4428e-02, 9.3137e-02, 9.2811e-02, 8.8335e-02,
               8.8756e-02, 9.1497e-02, 9.2905e-02, 9.0853e-02, 9.0384e-02, 9.1541e-02,
               9.0211e-02, 8.9793e-02, 8.9514e-02, 8.9517e-02, 9.1505e-02, 8.9631e-02,
               9.1136e-02, 9.2575e-02, 9.1392e-02, 9.3090e-02, 8.8292e-02, 9.0349e-02,
               9.1084e-02, 8.8323e-02, 9.2994e-02, 9.2237e-02, 9.3146e-02, 9.1452e-02,
               9.0734e-02, 8.8379e-02, 8.7978e-02, 8.9492e-02, 8.9843e-02, 9.0333e-02,
               8.8804e-02, 9.1494e-02, 8.7925e-02, 8.7843e-02, 8.3801e-02, 8.6106e-02,
               8.5067e-02, 8.7052e-02, 8.5589e-02, 8.4951e-02, 8.8796e-02, 8.7705e-02,
               8.5261e-02, 8.6430e-02, 8.8342e-02, 8.8025e-02, 8.7643e-02, 8.5078e-02,
               8.5278e-02, 8.6024e-02, 8.7616e-02, 8.7438e-02, 8.7544e-02, 8.5380e-02,
               8.4158e-02, 8.5203e-02, 8.2722e-02, 8.5083e-02, 8.1197e-02, 8.7108e-02,
               8.2733e-02, 8.5738e-02, 8.3412e-02, 8.4777e-02, 8.4626e-02, 8.4634e-02,
               8.3739e-02, 8.2266e-02, 8.4221e-02, 8.4054e-02, 8.5758e-02, 8.2645e-02,
               8.4006e-02, 7.8788e-02, 8.4486e-02, 8.0563e-02, 8.0541e-02, 8.0842e-02,
               8.4169e-02, 8.2613e-02, 8.1149e-02, 7.8860e-02, 8.0609e-02, 8.2913e-02,
               8.0485e-02, 7.9703e-02, 7.9695e-02, 7.9389e-02, 8.2552e-02, 8.1465e-02,
               8.1445e-02, 7.9665e-02, 7.9670e-02, 8.0048e-02, 7.9848e-02, 8.0464e-02,
               7.7984e-02, 8.2279e-02, 7.8785e-02, 8.5022e-02, 7.9626e-02, 8.0606e-02,
               7.4823e-02, 7.8597e-02, 8.1091e-02, 7.8011e-02, 7.6523e-02, 7.5026e-02,
               7.7059e-02, 7.5174e-02, 7.7957e-02, 7.5315e-02, 7.9572e-02, 7.6318e-02,
               7.8143e-02, 7.3121e-02, 7.5931e-02, 7.4652e-02, 7.5141e-02, 7.7491e-02,
               7.8188e-02, 7.5884e-02, 7.7047e-02, 7.8181e-02, 7.5196e-02, 7.8550e-02,
               7.7248e-02, 7.6953e-02, 7.7305e-02, 7.6908e-02, 7.8678e-02, 8.0238e-02,
               7.9623e-02, 7.8489e-02, 7.7812e-02, 7.5201e-02, 7.8717e-02, 7.8982e-02,
               8.0077e-02, 8.2038e-02, 8.2240e-02, 8.1377e-02, 8.6041e-02, 8.5393e-02,
               8.6972e-02, 8.8417e-02, 9.3373e-02, 9.6159e-02, 9.5587e-02, 9.9801e-02,
               1.0325e-01, 1.0168e-01, 1.0514e-01, 1.0577e-01, 1.0988e-01, 1.1001e-01,
               1.1305e-01, 1.1333e-01, 1.1623e-01, 1.2046e-01, 1.2137e-01, 1.2428e-01,
               1.2648e-01, 1.2644e-01, 1.2991e-01, 1.2944e-01, 1.3266e-01, 1.3463e-01,
               1.3557e-01, 1.4008e-01, 1.3995e-01, 1.3889e-01, 1.4354e-01, 1.4495e-01,
               1.4672e-01, 1.4734e-01, 1.5033e-01, 1.5016e-01, 1.5112e-01, 1.5460e-01,
               1.5805e-01, 1.6101e-01, 1.6337e-01, 1.6153e-01, 1.6472e-01, 1.6300e-01,
               1.6661e-01, 1.6895e-01, 1.6944e-01, 1.6995e-01, 1.7468e-01, 1.7271e-01,
               1.7640e-01, 1.7503e-01, 1.7833e-01, 1.7892e-01, 1.8304e-01, 1.8294e-01,
               1.8583e-01, 1.8594e-01, 1.8677e-01, 1.8520e-01, 1.8817e-01, 1.8782e-01,
               1.9088e-01, 1.9024e-01, 1.9014e-01, 1.9314e-01, 1.9423e-01, 1.9295e-01,
               1.9430e-01, 1.9401e-01, 1.9556e-01, 1.9566e-01, 1.9658e-01, 1.9605e-01,
               1.9823e-01, 1.9724e-01, 1.9796e-01, 1.9951e-01, 1.9981e-01, 2.0099e-01,
               2.0153e-01, 1.9743e-01, 1.9988e-01, 2.0170e-01, 1.9897e-01, 2.0311e-01,
               2.0209e-01, 2.0245e-01, 2.0290e-01, 2.0209e-01, 2.0181e-01, 1.9817e-01,
               1.9458e-01, 1.9286e-01, 2.0213e-01, 2.0538e-01, 2.0086e-01, 1.9685e-01,
               2.0023e-01, 2.0401e-01, 2.0201e-01, 2.0353e-01, 2.0378e-01, 2.0159e-01,
               2.0131e-01, 2.0087e-01, 2.0210e-01, 1.9795e-01, 2.0062e-01, 2.0165e-01,
               2.0268e-01, 2.0433e-01, 2.0166e-01, 2.0214e-01, 2.0108e-01, 2.0284e-01,
               2.0104e-01, 2.0234e-01, 2.0032e-01, 2.0359e-01, 2.0229e-01, 2.0072e-01,
               1.9968e-01, 2.0212e-01, 2.0426e-01, 2.0503e-01, 2.0392e-01, 2.0157e-01,
               2.0175e-01, 2.0400e-01, 2.0158e-01, 1.9996e-01, 2.0270e-01, 2.0349e-01,
               2.0334e-01, 2.0265e-01, 2.0367e-01, 2.0238e-01, 2.0331e-01, 2.0120e-01,
               2.0234e-01, 2.0096e-01, 2.0340e-01, 2.0465e-01, 2.0414e-01, 2.0553e-01,
               2.0291e-01, 2.0345e-01, 2.0253e-01, 2.0132e-01, 2.0301e-01, 2.0225e-01,
               2.0375e-01, 2.0342e-01, 2.0393e-01, 2.0516e-01, 2.0675e-01, 2.0631e-01,
               2.0441e-01, 2.0465e-01, 2.0596e-01, 2.0588e-01, 2.0446e-01, 2.0387e-01,
               2.0194e-01, 2.0229e-01, 2.0359e-01, 2.0409e-01, 2.0353e-01, 2.0305e-01,
               2.0471e-01, 2.0391e-01, 2.0498e-01, 2.0766e-01, 2.0672e-01, 2.0154e-01,
               2.0326e-01, 2.0317e-01, 2.0277e-01, 2.0531e-01, 2.0626e-01, 2.0435e-01,
               2.0557e-01, 2.0494e-01, 2.0621e-01, 2.0147e-01, 2.0644e-01, 2.0424e-01,
               2.0660e-01, 2.0694e-01, 2.0601e-01, 2.0631e-01, 2.0601e-01, 2.0491e-01,
               2.0629e-01, 2.0507e-01, 2.0348e-01, 2.0524e-01, 2.0845e-01, 2.0310e-01,
               2.0827e-01, 2.0647e-01, 2.0717e-01, 2.0573e-01, 2.0648e-01, 2.0851e-01,
               2.0575e-01, 2.0562e-01, 2.0633e-01, 2.0481e-01, 2.0438e-01, 2.0844e-01,
               2.0633e-01, 2.0631e-01, 2.0529e-01, 2.0399e-01, 2.0542e-01, 2.0661e-01,
               2.0364e-01, 2.0878e-01, 2.0419e-01, 2.0930e-01, 2.0845e-01, 1.2261e+10,
               1.9536e+11, 6.2071e+08, 2.6034e+15, 4.0171e+14, 2.0626e-01, 2.0435e-01,
               2.0389e-01, 9.4205e+13, 9.7306e+13, 2.0912e-01, 1.9879e+14, 2.0554e-01,
               2.0646e-01, 2.0964e-01, 7.2677e+13, 2.0913e-01, 2.0605e-01, 2.0791e-01,
               2.0558e-01, 7.2677e+13, 2.0752e-01, 2.0675e-01, 7.2677e+13, 2.0785e-01,
               2.0473e-01, 2.0653e-01, 2.0814e-01, 2.0548e-01, 1.4535e+14, 2.0737e-01,
               2.0683e-01, 2.0852e-01, 2.0345e-01, 1.2824e+16, 9.4276e+13, 9.7306e+13,
               7.9014e+14, 2.0687e-01, 2.0433e-01, 2.0707e-01, 2.0977e-01, 5.5639e-01,
               1.4535e+14, 2.0477e-01, 2.0297e-01, 2.0478e-01, 2.0740e-01, 2.0630e-01,
               2.0847e-01, 2.0659e-01, 2.0497e-01, 2.0428e-01, 2.0312e-01, 2.0128e-01,
               2.0229e-01, 2.0481e-01, 2.0288e-01, 1.9754e-01, 1.9882e-01, 1.9760e-01,
               2.0174e-01, 2.0139e-01, 1.4025e+12, 1.9461e+14, 1.1955e+10, 6.0545e+09,
               1.2643e+16, 1.9300e-01, 3.9259e+14, 1.9590e-01, 2.0127e+14, 4.8431e+10,
               1.2695e+16, 6.0814e+12, 4.8431e+10, 1.9536e+11, 1.9949e-01, 2.0003e+14,
               1.3616e+03, 1.9451e-01, 7.2677e+13, 2.0216e-01, 2.0075e-01, 1.4808e+14,
               9.9607e+13, 1.9825e-01, 1.9803e-01, 2.0102e-01]

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import datetime
import copy
import cv2
import statistics
import os.path as path
import glob
import math
import pandas as pd
import random
import shutil
import ctypes
import time
import optuna
import natsort
import GPUtil
import seaborn as sn  # Todo: gpu env
import os
import torchvision

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

from datetime import date
from spectral import *
from tempfile import mkdtemp
from PIL import Image
from matplotlib import pyplot as plt

plt.switch_backend('agg')
from functools import partial
from dataclasses import dataclass
from collections import OrderedDict
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms
# from pytorchtools import EarlyStopping
from skimage import io, transform  # TODO: download in gpu env
from mpl_toolkits.mplot3d import Axes3D
from sklearn.metrics import precision_recall_curve, auc, confusion_matrix, precision_score, \
    recall_score, classification_report, accuracy_score, f1_score, roc_curve, roc_auc_score
from torch.utils.tensorboard import SummaryWriter
from scipy import stats

# global parameters
storage_path = "E:/My Drive/StoragePath"
result_path = storage_path + "/ExpResults/tal_exp_results/"
data_path = result_path + "/no_note_background"  # if needed to resize again take photos from "not_resized" and "not_resized_img" and put in "no_note_background
data_path_img = result_path + "/no_note_background_img"
data_set_path = storage_path + "/Datasets/tal_datesets/corn_data_set"
resized_rgb_path = result_path + "/resized_rgb"
hdr_folder_name = "not_resized"  # "resized"
img_folder_name = "not_resized_img"  # "resizes_img"

global resized_path
global resized_img_path
global labels_df
global results_path

model_type = "binary"
if model_type == "binary":
    label_rank = 2
elif model_type == "regression":
    label_rank = 6
is_resize = False
only_resize = False
total_img = 20 # if no limit set to -1
is_volcani = True
labels = ["necrosis", "Burning", "Chlorosis", "Epinasty_curling", "Inhibited_growth", "Wilting", "Disturbed", "all"]
prior = [0.38, 0.03, 0.42, 0.01, 0.52, 0.27, 0.26, 0.53]
seed = 42
is_train = "continue_reset"  # /"normal" / "continue"  / "eval"  / "continue_reset

mode = "extra_neuron"  # / extra_neuron / neorun_layer / max_neuron / eval_only_max_neuron
if mode == "max_neuron":
    """net output is 7 neurons, loss calculation adds the max neuron and max Y"""
    extra_classes = 0
elif mode == "extra_neuron":
    """Net output is 8 neurons, last neuron loss is cal with max Y"""
    extra_classes = 1
elif mode == "eval_only_max_neuron":
    """evalute a net that outputs 8 neurons, turn the last neuron to be the max af all neurons
        Add max to y, and comapre the two for evaluation
    """
    extra_classes = 1
    is_train = "eval"
lr_type = "SGD"  # SGD / Adam
lr_adaptive = True

add_max_output = False
total_phenotypes = 7 + extra_classes
model_name = "lambda_l1_step_ratio_50_epoch_abs_2021-11-13k_17lambda_0.021183982025831938ap_0.8161412087035087"  # "all_channels_resolution_stride_2_2021-12-16_max_ap_epoch_57"   #"all_channels_resolution_stride_2"  # "lambda_l1_step_ratio_20_epoch_2021-11-10k_84"  # "lambda_l1_step_ratio_20_epoch"  #"no_normalaize_lambda_01_multi4_30epoch"  #"no_normalaize_lamda01_plus001"#  "lambda_01_adaptive_2021-09-09_k_195_ap_0.620"  # "lambda_01_adaptive_2021-09-09_k_45_ap_0.626"  #"lambda_01_adaptive_2021-09-09_k_195_ap_0.620"  #  "lambda_01_adaptive_2021-09-09_k_195_ap_0.620.pt"   #  # #1 weighted_BCE_2021-07-01"    #2weighted_BCE_2021-06-30"    # "weighted_BCE"
drop_out_p = 0.3
experiments_index = -1  # the index from file experiments for evaluation. only for is_train = eval

# is_L1 = True
channel_mask_mode = "none"  # "L1"  / "softmax" / "none" / "random_channels"/"all_channels"
lambda_adaptive = False
lambda1 = 0.8
max_k = 12
energy_value = 0.80
lambda_increase = 8
beta = 1
threshold = 0.001
lambda_period = 4
is_channel_mean = False
is_normalaize = False
top_num = 10
l1_step_ratio = 100
Wavelength = np.asarray(Wavelength)

is_resolution = True
stride_first_layer = 8
min_size = stride_first_layer * 7


def seed_everything(seed: int):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True
    pass


def cal_BCE_weights(parameters):
    indices = torch.nonzero(parameters['loss_mask'])
    indices = indices.flatten()
    parameters['thresholds'] = parameters['thresholds'][indices]
    parameters['BCE_weights'] = parameters['BCE_weights'][indices, :]
    parameters['BCE_weights'] = 1 / parameters['BCE_weights']
    parameters['BCE_weights'][:, 0] = parameters['BCE_weights'][:, 0] * parameters['BCE_param']
    parameters['BCE_weights'][:, 1] = parameters['BCE_weights'][:, 1] * (1 - parameters['BCE_param'])
    weight_batch = parameters['BCE_weights']
    for i in range(parameters['batch_size'] - 1):
        weight_batch = torch.cat((weight_batch, parameters['BCE_weights']))
    # weight_batch = 1 / weight_batch
    return weight_batch


def get_params(device):
    """
    define hyper-parameters
    :return: dict of hyper-parameters
    """
    parameters = {
        'dimension_reduction': 20,
        'dimension_span': 1.1,
        'n_classes': 7,
        'stride_first_layer': stride_first_layer,
        'size': (512, 256),
        'loss_mask': torch.tensor([1., 0., 1., 0., 1., 1., 1., 0.]).to(device),  # [1., 0., 1., 0., 1., 1., 1., 1.]
        'batch_size': 1,
        'depth': 1,
        'train_fraction': 0.8,  # till 12/10 - 0.7
        'test_fraction': 0,  # till 12/10 - 0.5
        'learning_rate': 0.005,
        'weight_decay': 0.0001,
        'dropout_p': 0.2,
        'epochs': 3,
        'tuning_mode': False,
        'grid_search_mode': False,
        'volcani': False,
        'workers': 1,
        'patience': 8,
        'delta': 0.001,
        'lr_patience': 4,
        'lr_delta': 0.01,
        'lr_decrease': 5,
        'lambda_patience': 15,
        'lambda_delta': 1,
        'threshold': 0.5,
        'thresholds': torch.tensor([0.81, 0.5, 0.65, 0.5, 0.976, 0.66, 0.785, 0.977]).to(device),
        # 'BCE_weights': torch.tensor([[0.62, 0.38], [0.96, 0.04], [0.58, 0.42], [0.98, 0.02], [0.48, 0.52], [0.72, 0.28],
        #                              [0.74, 0.26], [0.5, 0.5]]).to(device),
        'BCE_weights': torch.tensor([[0.62, 0.38], [0.8, 0.2], [0.50, 0.50], [0.8, 0.2], [0.50, 0.50], [0.72, 0.28],
                                     [0.74, 0.26], [0.6, 0.4]]).to(device),  # far all
        'BCE_param': 0.5,
        'tfms': transforms.Compose([transforms.RandomHorizontalFlip(),
                                    transforms.RandomVerticalFlip(),
                                    transforms.RandomAffine(degrees=40, scale=(.9, 1.1), shear=0),
                                    transforms.RandomPerspective(distortion_scale=0.2),
                                    transforms.ToTensor(),
                                    ])
    }
    weight_batch = cal_BCE_weights(parameters)
    parameters['weight_batch'] = weight_batch
    return parameters


def get_sparse_model_params():
    """
    define hyper-parameters
    :return: dict of hyper-parameters
    """
    parameters = {
        'dimension_reduction': 1,
        'dimension_span': 2,
        'n_classes': 7,
        'stride_first_layer': 2,
        'learning_rate': 0.005,
        'weight_decay': 0.0001,
    }
    return parameters


def get_tuning_params():
    """
    set ranges of values for the optimization part to choose from.
    """
    parameters = {
        'lr_low': 1e-6,
        'lr_high': 1e-2,
        'decay_low': 1e-6,
        'decay_high': 1e-2,
        'stride_first_layer_low': 1,
        'stride_first_layer_high': 4,
        'stride_first_layer_step': 1,
        'trials': 2,
        'dimension_reductions': [2, 4, 8, 16],
        'spacial_reduction': [2, 3, 4, 5],
        'visualizing_params': ["weight_decay", "lr"],
        'grid_search_params': ["dimension_reduction", "stride_first_layer"],
        'dimension_reduction': [4, 8],
        'stride_first_layer': [2, 4],
    }
    return parameters


"""create the model"""


class Conv2dAuto(nn.Conv2d):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.padding = (
            self.kernel_size[0] // 2, self.kernel_size[1] // 2)  # dynamic add padding based on the kernel_size


conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)  # create an instance of Conv2dAuto with kernel 3


class ResidualBlock(nn.Module):
    """set the basic format of a block"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.in_channels, self.out_channels = in_channels, out_channels
        # blocks in block
        self.blocks = nn.Identity()
        # in channels != out channels there is a sortcut to the residual that will fit outchannels
        self.shortcut = nn.Identity()

    def forward(self, x):
        residual = x
        if self.should_apply_shortcut: residual = self.shortcut(x)
        x = self.blocks(x)
        x += residual
        return x

    @property
    def should_apply_shortcut(self):
        return self.in_channels != self.out_channels


class ResNetResidualBlock(ResidualBlock):
    """set the shortcut"""

    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):
        super().__init__(in_channels, out_channels)
        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv  # conv = a conv2d with auto padding we created
        # the shorcat is a sequence of convolution and batch normalazation
        self.shortcut = nn.Sequential(OrderedDict(
            {
                'conv': nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,
                                  stride=self.downsampling, bias=False),  # expandind channels, downsampling by stride
                'bn': nn.BatchNorm2d(self.expanded_channels)  # BatchNorm2d

            })) if self.should_apply_shortcut else None  # is channels miss match

    @property
    def expanded_channels(self):
        return self.out_channels * self.expansion

    @property
    def should_apply_shortcut(self):
        return self.in_channels != self.expanded_channels


def conv_bn(in_channels, out_channels, conv, *args, **kwargs):
    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs),
                                      'bn': nn.BatchNorm2d(out_channels)}))


class ResNetBasicBlock(ResNetResidualBlock):
    """set the block to a sequence of 2 conv_bn which are a sequence of conv + bn"""
    expansion = 1

    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):
        super().__init__(in_channels, out_channels, *args, **kwargs)
        self.blocks = nn.Sequential(
            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),
            activation(),  # first convbn can downsample 2d
            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),
            nn.Dropout2d(drop_out_p)
            # second convbn - no downsample, possible channel expansion
        )


class ResNetLayer(nn.Module):
    """stack n layers one on each other, first layer can downsample if in!=out channels"""

    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):
        super().__init__()
        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'
        downsampling = 2 if in_channels != out_channels else 1
        # the block in the layer is a sequence of blocks
        self.blocks = nn.Sequential(
            block(in_channels, out_channels, *args, **kwargs, downsampling=downsampling),  # first block with downsample
            *[block(out_channels * block.expansion,
                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]
            # all other blocks no downsampling, possible expantion
        )

    def forward(self, x):
        x = self.blocks(x)
        return x


class ResnetDecoder(nn.Module):
    """
    This class represents the tail of ResNet. It performs a global pooling and maps the output to the
    correct class by using a fully connected layer.
    """

    def __init__(self, in_features, n_classes):
        super().__init__()
        self.avg = nn.AdaptiveAvgPool2d((1, 1))  # average along spacial area H * W
        self.decoder = nn.Linear(in_features, n_classes)  # fully connected with n_classes out neurons
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.avg(x)
        x = x.view(x.size(0), -1)  # flat the tensor
        x = self.decoder(x)
        x = self.sigmoid(x)
        return x


class ResNet(nn.Module):
    def __init__(self, in_channels, dimension_reduction, stride, dimension_span, n_classes, device):
        super().__init__()
        self.in_channels = in_channels
        self.dimension_reduction = dimension_reduction
        self.stride = stride
        self.dimension_span = dimension_span
        self.out1 = int(self.in_channels // self.dimension_reduction)  # todo: multiply instead of //
        self.out2 = int(self.out1 * self.dimension_span)
        self.out3 = int(self.out2 * self.dimension_span)
        self.conv1 = nn.Conv2d(self.in_channels, self.out1, 1, 1)
        # self.w_init = torch.empty(self.out1, in_channels)
        # nn.init.normal_(self.w_init)
        if channel_mask_mode == "L1" or channel_mask_mode == "softmax" or channel_mask_mode == "random_channels":
            self.channel_mask = torch.ones(1, in_channels).to(device)
            self.channel_mask = nn.Parameter(self.channel_mask, requires_grad=True)
            self.A = None
        if is_resolution:
            self.pool1 = nn.AvgPool2d(self.stride, stride=self.stride)
        else:
            self.pool1 = nn.MaxPool2d(self.stride, stride=self.stride)
        self.layer1 = ResNetLayer(self.out1, self.out1, block=ResNetBasicBlock, n=2)
        self.conv2 = nn.Conv2d(self.out1, self.out2, 3, 2)
        self.layer2 = ResNetLayer(self.out2, self.out2, block=ResNetBasicBlock, n=2)
        self.conv3 = nn.Conv2d(self.out2, self.out3, 3, 2)
        self.layer3 = ResNetLayer(self.out3, self.out3, block=ResNetBasicBlock, n=2)
        self.decoder = ResnetDecoder(self.out3, n_classes)
        # self.encoder = ResNetEncoder(in_channels, *args, **kwargs)
        # self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)

    def forward(self, x):
        if channel_mask_mode == "L1":
            x = torch.einsum('bchw,ic->bchw', x, self.channel_mask)
        elif channel_mask_mode == "softmax":
            self.A = torch.softmax(self.channel_mask / beta, dim=1)
            self.A = self.A * 730
            x = torch.einsum('bchw,ic->bchw', x, self.A)
        if is_resolution:
            x = self.pool1(x)
            #  save_rgb(result_path + "/RGB.png", hyperspectral_image, [430, 179 + 20, 108])
            x = F.relu(self.conv1(x))
        else:
            x = F.relu(self.conv1(x))
            x = self.pool1(x)
        x = self.layer1(x)
        x = F.relu(self.conv2(x))
        x = self.layer2(x)
        x = F.relu(self.conv3(x))
        x = self.layer3(x)
        # x = self.encoder(x)
        x = self.decoder(x)
        return x


"""Datasets """


class CustomDataSet(Dataset):
    def __init__(self, main_dir, image_dir, no_background_dir, no_background_imgdir, tfms, is_resize, df, size, device,
                 is_sparse=False, indices="", is_resolution=False, min_size=1):
        self.main_dir = main_dir
        self.device = device
        self.image_dir = image_dir
        self.no_background_dir = no_background_dir
        self.no_background_imgdir = no_background_imgdir
        self.tfms = tfms
        self.is_resize = is_resize
        self.size = size
        self.labels = df['label']
        self.total_imgs = df['img']  # natsort.natsorted(img_list['img'])
        self.list_IDs = df.index
        self.is_sparse = is_sparse
        self.indices = indices
        self.is_resolution = is_resolution
        self.min_size = min_size

    def __len__(self):
        return len(self.total_imgs)

    def __getitem__(self, idx):
        ID = self.list_IDs[idx]
        if self.is_resize:
            hdr_loc = os.path.join(self.no_background_dir, self.total_imgs[ID])  # .replace("resized", "no_note"))
            img_loc = os.path.join(self.no_background_imgdir, self.total_imgs[ID].replace(".hdr", ".img"))
            image = envi.open(hdr_loc, img_loc)
            resized = resize(image, self.size)
            """get mean and std from top 2 rows for background"""
            mean = np.median(image[:, 0:1, :], axis=(0, 1))  # median for every band
            black_std = np.std(image[:, 0:1, :], axis=(0, 1))
            final_image = pad_img(resized, self.size, mean, black_std, image)
        else:
            hdr_loc = os.path.join(self.main_dir, self.total_imgs[ID])
            img_loc = os.path.join(self.image_dir, self.total_imgs[ID].replace(".hdr", ".img"))
            image = envi.open(hdr_loc, img_loc)
            if self.is_resolution:
                image = pad_for_resolution(image, self.min_size)
            final_image = np.zeros((image.shape[0], image.shape[1], image.shape[2]))
            final_image[:, :, :] = image[:, :, :]
        x = []
        # set a seed so the same transforms are applied to each channel
        seed = np.random.randint(2147483647)
        for ch in range(final_image.shape[2]):
            if self.is_sparse == True and ((ch in self.indices[0, :].tolist()) == False):
                continue
            random.seed(seed)
            channel_img = self.tfms(Image.fromarray(final_image[:, :, ch]))
            if is_normalaize:
                norm_transorm = torch.nn.Sequential(
                    transforms.Normalize(channel_means[ch], channel_std[ch])
                )
                channel_img = norm_transorm(channel_img)
            x.append(channel_img)
        # this is the multichannel transformed image (a torch tensor)
        img_tfm = torch.cat(x)
        y = self.labels[ID].values
        img_tfm = img_tfm.to(self.device)
        y = torch.FloatTensor(y).to(self.device)
        return img_tfm, y


# Early stopping


class EarlyStopping:
    """Early stops the training if validation loss doesn't improve after a given patience."""

    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print, value_name="loss"):
        """
        Args:
            patience (int): How long to wait after last time validation loss improved.
                            Default: 7
            verbose (bool): If True, prints a message for each validation loss improvement.
                            Default: False
            delta (float): Minimum change in the monitored quantity to qualify as an improvement.
                            Default: 0
            path (str): Path for the checkpoint to be saved to.
                            Default: 'checkpoint.pt'
            trace_func (function): trace print function.
                            Default: print
        """
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
        self.path = path
        self.value_name = value_name
        self.trace_func = trace_func

    def __call__(self, val_loss, model):
        score = -val_loss
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.delta:
            self.counter += 1
            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        '''Saves model when validation loss decrease.'''
        if self.verbose:
            # self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
            self.trace_func(
                f'{self.value_name} decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')

        torch.save(model.state_dict(), self.path + "_" + str(date.today()) + ".pt")
        self.val_loss_min = val_loss


"""functions for main"""


# Loading Data

def pad_for_resolution(image, min_size):
    is_pad = False
    (height, width) = image.shape[:2]
    if height < min_size:
        height = min_size
        is_pad = True
    if height / min_size < 2:
        width_min = min_size * 2
    else:
        width_min = min_size
    if width < width_min:
        # if is_pad == True:
        #     width = min_size * 2
        # else:
        width = width_min
        is_pad = True
    if is_pad:
        mean = np.median(image[:, 0:1, :], axis=(0, 1))  # median for every band
        black_std = np.std(image[:, 0:1, :], axis=(0, 1))
        image = pad_img(image, (width, height), mean, black_std, is_save=False)
    return image


def resize_and_save(params):
    dir_list = os.listdir(data_path)
    for i, img in enumerate(dir_list):
        if total_img > 0:
            if i > total_img:
                break
        if ".img" in img:  # or "2019-12-25" in img:
            continue
        file_name = resized_path + "/" + img.replace("no_note.hdr", "resized.hdr")
        if os.path.isfile(file_name):
            continue
        image_data = envi.open(f'{data_path}/{img}')
        resized = resize(image_data, params['size'])
        """get mean and std from top 2 rows for background"""
        mean = np.median(image_data[:, 0:1, :], axis=(0, 1))  # median for every band
        black_std = np.std(image_data[:, 0:1, :], axis=(0, 1))
        final_image = pad_img(resized, params['size'], mean, black_std, img)
    pass


def get_data(path, resized_path):
    """
    :param path: data path
    :param size: width and length of images (tuple)
    :return:  dictionary of np.arrays of images and labels
    """
    img_list = []
    label_list = []
    group_list = []
    print("Getting data from source...")

    if not is_resize:
        dir_list = os.listdir(resized_path)
    else:
        dir_list = os.listdir(path)
    for i, img in enumerate(dir_list):
        if total_img > 0:
            if i > total_img:
                break
        if ".img" in img:  # or "2019-12-25" in img
            continue
        img_list.append(img)
        labels, group = get_labels(img)
        label_list.append(labels)
        group_list.append(group)

    """split into groups"""
    df = pd.DataFrame(
        {'img': img_list,
         'label': label_list,
         'group': group_list
         })
    if model_type == "regression":
        df['label'] = df['label'] / label_rank
    elif model_type == "binary":
        df['label'] = df['label'] - 1
    df_train = pd.DataFrame(
        columns=['img', 'label', 'group'])
    df_val = pd.DataFrame(
        columns=['img', 'label', 'group'])
    df_test = pd.DataFrame(
        columns=['img', 'label', 'group'])

    for phenotype in range(total_phenotypes - extra_classes + 1):
        df_phenotype = df[df['group'] == phenotype]
        train_df_phenotype = df_phenotype.sample(frac=params['train_fraction'])
        val_test_df_phenotype = df_phenotype.drop(train_df_phenotype.index)
        test_df_phenotype = val_test_df_phenotype.sample(frac=params['test_fraction'])
        val_df_phenotype = val_test_df_phenotype.drop(test_df_phenotype.index)
        df_train = df_train.append(train_df_phenotype)
        df_val = df_val.append(val_df_phenotype)
        df_test = df_test.append(test_df_phenotype)

    # shuffle data frame
    df_train = df_train.sample(frac=1)
    df_val = df_val.sample(frac=1)
    df_test = df_test.sample(frac=1)

    print("Getting data done.")
    return df_train, df_val, df_test


def resize(image_data, size):
    """resizing by the larger aspect ratio"""
    (w_target, h_target) = size
    (h_origin, w_origin) = image_data.shape[:2]
    h_ratio = h_target / h_origin
    w_ratio = w_target / w_origin
    if h_ratio > w_ratio:
        ratio = w_ratio
    else:
        ratio = h_ratio
    dim = (int(w_origin * ratio), int(h_origin * ratio))
    resized_img = np.zeros((dim[1], dim[0], image_data.shape[2]))
    # print(dim)
    for b in range(image_data.shape[2]):
        resized_band = cv2.resize(image_data[:, :, b], dim, interpolation=cv2.INTER_AREA)
        resized_img[:, :, b] = resized_band
    return resized_img


def pad_img(resized, size, mean, black_std, img_name="", is_save=True):
    """
    pad the image with normal dist of background
    taking mean and std from 2 top rows
    """
    (w_target, h_target) = size
    (h_origin, w_origin) = resized.shape[:2]
    final_image = np.zeros((h_target, w_target, resized.shape[2]))
    for band in range(resized.shape[2]):
        padded_img = np.random.normal(mean[band], black_std[band], (h_target, w_target))
        # compute center offset
        xx = (w_target - w_origin) // 2
        yy = (h_target - h_origin) // 2
        # enter image
        padded_img[yy:yy + h_origin, xx:xx + w_origin] = resized[:, :, band].reshape(
            (resized.shape[0], resized.shape[1]))
        final_image[:, :, band] = padded_img
    if only_resize:
        img_str = img_name.replace("D:/My Drive/StoragePath/ExpResults/tal_exp_results/no_note_background_img", "")
        save_rgb(resized_rgb_path + "/" + img_str.replace("no_note.hdr", "resized_rgb.png"), final_image,
                 [430, 179 + 20, 108])
        envi.save_image(resized_path + "/" + img_str.replace("no_note.hdr", "resized.hdr"), final_image,
                        dtype=np.float32)
    else:
        if is_save:
            img_str = img_name.filename.replace(
                "D:/My Drive/StoragePath/ExpResults/tal_exp_results/no_note_background_img",
                "")  # todo change back when running model
            save_rgb(resized_rgb_path + img_str.replace("no_note.img", "resized_rgb.png"), final_image,
                     [430, 179 + 20, 108])
            envi.save_image(resized_path + "/" + img_str.replace("no_note.img", "resized.hdr"), final_image,
                            dtype=np.float32)
    return final_image


def get_labels(img):
    date = img.split('_')[2]
    date = date.replace('-', '')
    date = int(date[2:])
    # img_name = img.split('_')[1]
    # img_name = img_name.replace('plot', '')
    if not ("plot" in img):
        print("found image not of plot in no_note_background")
        return False
    plot_num = int(img.split('plot')[1].split("_")[0])
    if plot_num > 0:
        # print(f'getting labels')
        labels = labels_df[(labels_df['SampleDate'] == date) & (labels_df['plot'] == plot_num)].iloc[0]
        group = labels['group']
        labels = labels.drop(labels=['plot', 'SampleDate', 'Y_cropped', 'group', 'Bleaching'])
        if model_type == "binary":
            labels[labels > 1] = 2
    return labels, group


def load_data(df_train, df_val, df_test, params, device, is_sparse=False, indices=""):
    tfms = params['tfms']
    if not is_sparse:
        train_dataset = CustomDataSet(resized_path, resized_img_path, data_path, data_path_img, tfms=tfms,
                                      is_resize=is_resize, df=df_train, size=params['size'], device=device,
                                      is_resolution=is_resolution, min_size=min_size)
        val_dataset = CustomDataSet(resized_path, resized_img_path, data_path, data_path_img, tfms=tfms,
                                    is_resize=is_resize, df=df_val, size=params['size'], device=device,
                                    is_resolution=is_resolution, min_size=min_size)
        test_dataset = CustomDataSet(resized_path, resized_img_path, data_path, data_path_img, tfms=tfms,
                                     # params['tfms']
                                     is_resize=is_resize, df=df_test, size=params['size'], device=device,
                                     is_resolution=is_resolution, min_size=min_size)
    else:
        train_dataset = CustomDataSet(resized_path, resized_img_path, data_path, data_path_img, tfms=tfms,
                                      is_resize=is_resize, df=df_train, size=params['size'], device=device,
                                      is_sparse=is_sparse, indices=indices, is_resolution=is_resolution,
                                      min_size=min_size)
        val_dataset = CustomDataSet(resized_path, resized_img_path, data_path, data_path_img, tfms=tfms,
                                    is_resize=is_resize, df=df_val, size=params['size'], device=device,
                                    is_sparse=is_sparse, indices=indices, is_resolution=is_resolution,
                                    min_size=min_size)
        test_dataset = CustomDataSet(resized_path, resized_img_path, data_path, data_path_img, tfms=tfms,
                                     # params['tfms']
                                     is_resize=is_resize, df=df_test, size=params['size'], device=device,
                                     is_sparse=is_sparse, indices=indices, is_resolution=is_resolution,
                                     min_size=min_size)
    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=False,
                              num_workers=params['workers'], drop_last=True)
    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False,
                            num_workers=params['workers'], drop_last=True)
    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False,
                             num_workers=params['workers'], drop_last=True)
    return train_loader, test_loader, val_loader


# Creating and training model


def init_model(params, input_channel, n_classes, device):
    ResNetModel = ResNet(input_channel, params["dimension_reduction"], params["stride_first_layer"],
                         params["dimension_span"], n_classes, device)
    criterion = nn.MSELoss()
    if lr_type == "SGD":
        optimizer = torch.optim.SGD(ResNetModel.parameters(), lr=params["learning_rate"],
                                    weight_decay=params["weight_decay"])
    elif lr_type == "Adam":
        optimizer = torch.optim.Adam(ResNetModel.parameters(), lr=params["learning_rate"],
                                     weight_decay=params["weight_decay"])
    ResNetModel.to(device)
    return ResNetModel, optimizer


def add_max_to_tensor(tensor, dim):
    max_input = torch.max(tensor, dim=dim).values
    m = max_input.unsqueeze(-1)
    tensor = torch.cat((tensor, m), dim=dim)
    return tensor


def set_last_neuron_max(tensor, params, dim):
    # indices = torch.nonzero(params['loss_mask']).flatten()
    max_input = torch.max(tensor, dim=dim).values
    m = max_input.unsqueeze(-1)
    # tensor = torch.cat((tensor, m), dim=dim)
    tensor[:, -1] = max_input
    return tensor


def unpack_batches(batched):
    temp = torch.Tensor(len(batched), batched[0].shape[0], batched[0].shape[1]).to(device)
    unbatched = torch.cat(batched, out=temp)
    return unbatched


def cal_train_ap_acc_old(params, total_scores, total_labels):
    # Unpack tensors from batches
    total_scores = unpack_batches(total_scores)
    total_labels = unpack_batches(total_labels)
    # #mask phenotypes
    # indices = torch.nonzero(params['loss_mask']).flatten()
    # total_scores = total_scores[:, indices]
    # total_labels = total_labels[:, indices]
    # per phenotype ap
    ap = {}
    f1 = {}
    for col in range(total_scores.shape[1]):
        ap[col], f1[col] = plot_recall_precision(total_labels[:, col].cpu(), total_scores[:, col].cpu(), is_print=True)
    average_ap = sum(ap.values()) / len(ap)
    return average_ap, ap, f1


def cal_train_ap_acc(params, total_scores, total_labels, n, total_predictions, max_ap, max_binary_ap, max_f1, epoch,
                     max_roc, ap_f1):
    # nonlocal max_ap,]
    # nonlocal max_binary_ap
    # nonlocal max_f1
    # nonlocal i
    fig, axs = plt.subplots(n, figsize=(24, 24))
    fig2, axs2 = plt.subplots(n, figsize=(24, 24))
    # Unpack tensors from batches
    total_scores = unpack_batches(total_scores)
    total_labels = unpack_batches(total_labels)
    total_predictions = unpack_batches(total_predictions)

    labels_ranking = np.arange(0, label_rank)
    # per phenotype ap
    ap = {}
    f1 = {}
    for col in range(total_scores.shape[1]):
        ap[col], f1[col] = plot_recall_precision(total_labels[:, col].cpu(), total_scores[:, col].cpu(), is_print=True,
                                                 axs=axs2,
                                                 index=col, title=str(col))
        cm_per_phenotype, axs = plot_confusion_matrics(total_predictions[:, col], total_labels[:, col],
                                                       col, labels_ranking, axs, col)
    average_ap = sum(ap.values()) / len(ap)

    # print every epoch last model
    for ax in axs2.flat:
        ax.set(xlabel='recall', ylabel='precision')
    # Hide x labels and tick labels for top plots and y ticks for right plots.
    for ax in axs2.flat:
        ax.label_outer()
    # fig = fig.get_figure()
    fig2.savefig(results_path + "/" + "Recall_Precision_in_train" + model_name + ".png")

    # max metrics models
    if average_ap > max_ap:
        ap_f1 = f1[2]
        max_ap = average_ap
        torch.save(net.state_dict(),
                   model_path + "_" + str(date.today()) + "_max_ap_epoch_" + str(epoch) + ".pt")
        fig2.savefig(results_path + "/" + "Recall_Precision_in_train_max_ap" + model_name + ".png")

    if ap[2] > max_binary_ap:
        max_binary_ap = ap[2]
        torch.save(net.state_dict(),
                   model_path + "_" + str(date.today()) + "_max_binary_ap_epoch_" + str(epoch) + ".pt")
        fig2.savefig(results_path + "/" + "Recall_Precision_in_train_max_binary_ap" + model_name + ".png")

    plt.close()

    for ax in axs.flat:
        ax.set(xlabel='predicted', ylabel='actual')
    # Hide x labels and tick labels for top plots and y ticks for right plots.
    for ax in axs.flat:
        ax.label_outer()

    # fig = fig.get_figure()
    fig.savefig(results_path + "/" + "Confusion_Matrix_in_train" + model_name + ".png")

    if f1[2] > max_f1:
        max_f1 = f1[2]
        torch.save(net.state_dict(),
                   model_path + "_" + str(date.today()) + "_max_f1_epoch_" + str(epoch) + ".pt")
        fig.savefig(results_path + "/" + "Confusion_Matrix_in_train_max_f1" + model_name + ".png")

    plt.close()

    roc_auc, max_roc = plot_roc_curve(total_labels[:, 2].cpu(), total_scores[:, 2].cpu(),
                                      "binary_phenotype_" + model_name, is_train=True, max_roc=max_roc)
    if roc_auc >= max_roc:
        max_roc = roc_auc
        torch.save(net.state_dict(),
                   model_path + "_" + str(date.today()) + "_max_ap_epoch_" + str(epoch) + ".pt")

    (th, acc) = opt_threshold_acc(total_labels[:, 2].cpu(), total_scores[:, 2].cpu())

    return average_ap, ap, f1, max_ap, max_binary_ap, max_f1, max_roc, ap_f1, acc


def add_L1_reg(loss, model, lambda2):
    # all_linear1_params = torch.cat([x.view(-1) for x in model.w.parameters()])
    # print(f"The channel mask tensor: {model.channel_mask}, lambda: {lambda1}")
    l1_regularization = lambda2 * torch.norm(model.channel_mask, 1)
    return loss + l1_regularization


def add_L1_softmax(loss, model):
    # all_linear1_params = torch.cat([x.view(-1) for x in model.w.parameters()])
    # print(f"The channel mask tensor: {model.channel_mask}, lambda: {lambda1}")
    l1_regularization = lambda1 * torch.norm(model.channel_mask, 1)
    return loss + l1_regularization


def get_k_value_zscore(z_value, values):
    z_scores = stats.zscore(values, axis=1)
    k_indicies = z_scores > -z_value
    not_k_indicies = z_scores <= -z_value
    k = np.sum(k_indicies)
    # k_values = values[z_scores > -z_value]
    return k, not_k_indicies


def get_k_value(energy_precent, values):
    AW = np.abs(values)
    Sorted_AW = -np.sort(-AW)  # sort in descending order
    Energy_CDF = np.divide(np.cumsum(Sorted_AW), np.sum(AW))
    Inds = np.argwhere(Energy_CDF < energy_precent)
    k = Inds.shape[0]
    sorted_indices = np.argsort(-values)
    not_k_indicies = sorted_indices[:, k:]
    return k, not_k_indicies


def add_mean_std_per_band(img, mean_list, var_list):
    mean_per_band = img.mean(axis=(2, 3))
    mean_per_band = torch.reshape(mean_per_band, shape=(-1,))
    var_per_band = img.var(axis=(2, 3))
    var_per_band = torch.reshape(var_per_band, shape=(-1,))
    # mean_list.append(mean_per_band)
    # var_list.append(var_per_band)
    mean_list += mean_per_band
    var_list += var_per_band


def check_mean_per_band_after_normalaize(mean_list, var_list, n_images):
    # mean_per_channel_tensor = torch.stack(mean_list)
    # mean_per_channel_all_img = torch.mean(mean_per_channel_tensor, dim=0)
    # plot_large_bar_chart(np.arange(mean_per_channel_all_img.shape[0]), mean_per_channel_all_img, "channel",
    #                      "mean_per_band", "channel_mean_vlaues")
    # std_per_channel_tensor = torch.stack(var_list)
    # std_per_channel_all_img = torch.mean(std_per_channel_tensor, dim=0)
    # plot_large_bar_chart(np.arange(std_per_channel_all_img.shape[0]), std_per_channel_all_img, "channel",
    #                      "std_per_band", "channel_std_vlaues")

    mean_list /= n_images
    var_list /= n_images
    std = torch.sqrt(var_list)
    print(f"mean per channel: {mean_list}")
    print(f"std per channel: {std}")
    plot_large_bar_chart(np.arange(mean_list.shape[0]), mean_list, "channel",
                         "mean_per_band", "channel_mean_vlaues")
    plot_large_bar_chart(np.arange(std.shape[0]), std, "channel",
                         "std_per_band", "channel_std_vlaues")
    return mean_list, std


def plot_large_bar_chart(x, y, x_label, y_label, title):
    plt.figure(figsize=(20, 10))
    plt.bar(x, y)
    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.xticks(rotation=90)
    plt.savefig(title)
    plt.close()
    pass


def cal_mean_std_per_band_and_plot(all_image):
    mean_per_channel_all_img = torch.mean(all_image, dim=0)
    print(f'mean per channel: {mean_per_channel_all_img}')
    plot_large_bar_chart(np.arange(mean_per_channel_all_img.shape[0]), mean_per_channel_all_img, "channel",
                         "mean_per_band", "channel_mean_vlaues")
    std_per_channel_all_img = torch.std(all_image, dim=0)
    print(f"std per channel: {std_per_channel_all_img}")
    plot_large_bar_chart(np.arange(std_per_channel_all_img.shape[0]), std_per_channel_all_img, "channel",
                         "std_per_band", "channel_std_vlaues")
    return mean_per_channel_all_img, std_per_channel_all_img


def get_all_images():
    all_image_list = []
    for b, (X_train, y_train) in enumerate(train_loader):
        all_image_list.append(X_train)
        if b > 10:
            break
    all_image_list
    all_image_list = torch.stack(all_image_list)
    return all_image_list


def cal_plot_mean_std_images():
    all_image_tensor = get_all_images()
    mean, std = cal_mean_std_per_band_and_plot(all_image_tensor)


def plot_channel_tensor(net, epoch, k):
    global Wavelength
    net.channel_mask.requires_grad = False
    cm = net.channel_mask.cpu()
    np_cm = np.asarray(cm)
    # Wavelength = np.asarray(Wavelength)
    Wavelength = Wavelength[0:730]
    plot_large_bar_chart(Wavelength, np_cm[0], "channel", "energy",
                         "mask tensor energy k=" + str(k) + "epoch " + str(epoch))
    net.channel_mask.requires_grad = True


def get_top_channels(tensor, top_num):
    tensor_abs = torch.abs(tensor)
    indices = torch.topk(tensor_abs, top_num).indices
    values = torch.topk(tensor_abs, top_num).values
    top_values = torch.sum(values)
    energy = top_values / torch.sum(tensor_abs)
    top_waves = Wavelength[indices.cpu().numpy()[0]]
    return energy, top_waves, indices


def opt_threshold_acc(y_true, y_pred):
    A = list(zip(y_true, y_pred))
    A = sorted(A, key=lambda x: x[1])
    total = len(A)
    tp = len([1 for x in A if x[0]==1])
    tn = 0
    th_acc = []
    for x in A:
        th = x[1]
        if x[0] == 1:
            tp -= 1
        else:
            tn += 1
        acc = (tp + tn) / total
        th_acc.append((th, acc))
    return max(th_acc, key=lambda x: x[1])


def train_model(train_loader, test_loader, params, optimizer, net):
    # net.eval()
    global lambda1
    global beta
    global channel_mask_mode
    global model_name
    start_time = time.time()
    train_losses = []
    test_losses = []
    test_ap_list = []
    binary_ap_list = []
    channel_mask_list = []
    k_list = []
    top_channels_list = []
    energy_list = []
    mask_weights = []
    lr_list = []
    L1_step_list = []
    lambda_list = []
    max_ap = 0
    max_binary_ap = 0
    max_f1 = 0
    max_roc = 0
    max_acc = 0
    ap_f1 = 0
    mean_per_channel_list = torch.empty([730])  # []
    std_per_channel_list = torch.empty([730])  # []
    lambda1 = 1 / (params["learning_rate"] * l1_step_ratio)
    # initialize the early_stopping object
    early_stopping = EarlyStopping(patience=params['patience'], verbose=True, delta=params['delta'], path=model_path,
                                   value_name="AP")
    if lr_adaptive:
        early_stopping_lr = EarlyStopping(patience=params['lr_patience'], verbose=True, delta=params['lr_delta'],
                                          path=model_path, value_name="AP")
    if lambda_adaptive and (channel_mask_mode == "L1" or channel_mask_mode == "softmax"):
        early_stopping_lambda = EarlyStopping(patience=params['lambda_patience'], verbose=True,
                                              delta=params['lambda_delta'],
                                              path=model_path, value_name="k")
    tb = SummaryWriter()
    for i in range(params['epochs']):
        # train batches
        running_loss = 0.0
        b_num = 0
        for b, (X_train, y_train) in enumerate(train_loader):
            # forward
            b_num += 1  # params['batch_size']
            print(b_num)
            if is_channel_mean and i == 0:
                add_mean_std_per_band(X_train, mean_per_channel_list, std_per_channel_list)
            y_pred = net(X_train.float())

            # mask phenotypes and adjust tensors by mode
            indices = torch.nonzero(params['loss_mask']).flatten()
            y_pred = y_pred[:, indices]
            if mode == "max_neuron":
                """add neuron of max for loss cal"""
                y_pred = add_max_to_tensor(y_pred, dim=1)
            y_train = add_max_to_tensor(y_train, dim=1)
            y_train = y_train[:, indices]

            if model_type == "regression":
                loss = cal_loss_huber(y_pred, y_train.float())
            elif model_type == "binary":
                # if mode == "max_neuron":
                #     y_pred = add_max_to_tensor(y_pred, dim=1)
                #     y_train = add_max_to_tensor(y_train, dim=1)
                #     loss = cal_loss_BCE(y_pred, y_train.float(), params['weight_batch'], params['batch_size'])
                # elif mode == "extra_neuron":
                #     y_train = add_max_to_tensor(y_train, dim=1)
                #     loss = cal_loss_BCE(y_pred, y_train.float(), params['weight_batch'], params['batch_size'])
                loss = cal_loss_BCE(y_pred, y_train.float(), params['weight_batch'], params['batch_size'])
                if channel_mask_mode == "L1":
                    loss = add_L1_reg(loss, net, lambda1)
            # backprop
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            # scaled_loss = loss.item() / params['batch_size']
            if b % 50 == 0:
                print(f'epoch: {i + 1:2},   batch: {b_num}   loss: {loss.item():10.8f}')

        if torch.cuda.is_available():
            print("GPU Utilization:")
            GPUtil.showUtilization()

        # Run the testing batches
        total_scores = []
        total_labels = []
        total_predictions = []
        test_running_loss = 0.0
        net.eval()
        with torch.no_grad():
            b_num_test = 0
            for b, (X_test, y_test) in enumerate(test_loader):
                b_num_test += 1  # params['batch_size']
                y_pred = net(X_test.float())

                # mask phenotypes and adjust tensors by mode
                indices = torch.nonzero(params['loss_mask']).flatten()
                y_pred = y_pred[:, indices]
                if mode == "max_neuron":
                    """add neuron of max for loss cal"""
                    y_pred = add_max_to_tensor(y_pred, dim=1)
                y_test = add_max_to_tensor(y_test, dim=1)
                y_test = y_test[:, indices]
                prediction = (y_pred > params['thresholds']).float()
                if model_type == "regression":
                    test_loss = cal_loss_huber(y_pred, y_test.float())
                elif model_type == "binary":
                    test_loss = cal_loss_BCE(y_pred, y_test.float(), params['weight_batch'], params['batch_size'])
                test_running_loss += test_loss.item()

                total_scores.append(y_pred)
                total_labels.append(y_test)
                total_predictions.append(prediction)

        net.train()
        if is_channel_mean and i == 0:
            mean, var = check_mean_per_band_after_normalaize(mean_per_channel_list, std_per_channel_list, b_num)

        ap, ap_all, f1, max_ap, max_binary_ap, max_f1, max_roc, ap_f1, acc = cal_train_ap_acc(params, total_scores,
                                                                                         total_labels, y_pred.shape[1],
                                                                                         total_predictions, max_ap,
                                                                                         max_binary_ap, max_f1, i,
                                                                                         max_roc, ap_f1)

        if max_acc < acc:
            max_acc = acc

        average_test_epoch_loss = test_running_loss / b_num_test
        average_epoch_loss = running_loss / b_num
        train_losses.append(average_epoch_loss)
        test_ap_list.append(ap)
        binary_ap_list.append(ap_all[2])
        test_losses.append(average_test_epoch_loss)
        print(f'epoch: {i + 1:2}   average epoch train loss: {average_epoch_loss:10.8f}')
        print(f'epoch: {i + 1:2}   average epoch test loss: {average_test_epoch_loss:10.8f}')
        print(f'epoch: {i + 1:2}   ap: {ap:10.8f}')

        ##### check k value and update lambda or end learning for mask vector
        is_print_ap_K = False
        if (channel_mask_mode == "L1" or channel_mask_mode == "softmax") and is_train == "normal":
            lr_list.append(params["learning_rate"])
            lambda_list.append(lambda1)
            l1_step = lambda1 * params["learning_rate"]
            L1_step_list.append(l1_step)
            k, not_k_indicies = get_k_value(energy_value, values=net.channel_mask.cpu().detach().numpy())
            torch.save(net.state_dict(),
                       model_path + "_" + str(date.today()) + "k_" + str(k) + "lambda_" + str(lambda1) + "ap_" + str(
                           ap) + ".pt")
            channel_mask_list.append(net.channel_mask.cpu().tolist())
            k_list.append(k)
            plot_channel_tensor(net, i, k)
            energy_top, top_channels, top_indices = get_top_channels(net.channel_mask.cpu(), top_num)
            top_channels = np.sort(top_channels, axis=None)
            top_channels = top_channels.tolist()
            top_channels_list.append(top_channels)
            energy_list.append(energy_top.detach().numpy().item())
            # if k small enough freeze channel mask
            if k < max_k or i == params['epochs'] - 1:  # k < max_k:
                torch.save(net.state_dict(),
                           model_path + "_" + str(date.today()) + "freeze_channel_mask" + ".pt")
                print(f"The Final channel mask tensor: {net.channel_mask}, lambda: {lambda1}")
                net.channel_mask.requires_grad = False
                if channel_mask_mode == "L1":
                    net.channel_mask[0, not_k_indicies.reshape((not_k_indicies.shape[1],))] = 0.
                elif channel_mask_mode == "softmax":
                    net.channel_mask[0, not_k_indicies.reshape((not_k_indicies.shape[1],))] = -math.inf
                channel_mask_mode = ""
                is_print_ap_K = True
            elif lambda_adaptive:
                early_stopping_lambda(k, net)
                if early_stopping_lambda.early_stop:
                    torch.save(net.state_dict(),
                               model_path + "_" + str(date.today()) + "_lambda" + str(lambda1) + ".pt")
                    print(f"The channel mask tensor: {net.channel_mask}, lambda: {lambda1}")
                    if channel_mask_mode == "L1":
                        lambda1 = lambda1  # * lambda_increase
                    elif channel_mask_mode == "softmax":
                        beta = beta + 2
                    early_stopping_lambda = EarlyStopping(patience=params['lambda_patience'], verbose=True,
                                                          delta=params['lambda_delta'],
                                                          path=model_path, value_name="k")
            ### increase lambda/beta every number of epochs
            if i % lambda_period == 0:
                if channel_mask_mode == "L1":
                    lambda1 = lambda1 * lambda_increase  #
                elif channel_mask_mode == "softmax":
                    print(f"The channel1_stepl mask tensor: {net.channel_mask}, lambda: {lambda1}")
                    beta = beta + 2

        # update lr if no improvement in AP
        if lr_adaptive:
            early_stopping_lr(-ap, net)
            if early_stopping_lr.early_stop:
                params["learning_rate"] = params["learning_rate"] / params['lr_decrease']
                params["lr_delta"] = params["lr_delta"] / params['lr_decrease']
                print(f'Early stop lr smaller: {params["learning_rate"]:10.8f}')
                for g in optimizer.param_groups:
                    g['lr'] = params["learning_rate"]

                early_stopping_lr = EarlyStopping(patience=params['lr_patience'], verbose=True,
                                                  delta=params['lr_delta'],
                                                  path=model_path, value_name="AP")
        # Early Stop
        early_stopping(-ap, net)
        if early_stopping.early_stop:
            print("Early stopping")
            # break

        for name, param in net.named_parameters():
            # print(f'nets params {name}: {param}')   #  {param.data}
            mean_mask_tensor = torch.mean(torch.abs(param)).item()
            mask_weights.append(mean_mask_tensor)
            lambda1 = mean_mask_tensor / (params["learning_rate"] * l1_step_ratio)
            break
            # print(f'mean of weight: {}')

    # tensorBoard
    # images, labels = next(iter(train_loader))
    # grid = torchvision.utils.make_grid(images[:, (430, 179 + 20, 108), :, :])
    # tb.add_image("images", grid)
    # # tb.add_graph(net, images)
    # tb.add_scalars("Loss", {"Train Loss": average_epoch_loss, "Validation Loss": average_test_epoch_loss}, i + 1)
    # tb.add_scalar("Validation Loss", average_test_epoch_loss, i + 1)
    # tb.close()

    duration = time.time() - start_time
    expirement_df = pd.read_csv(results_path + "/experiments.csv")
    if not hasattr(net, 'channel_mask'):
        expirement_df = expirement_df.append({'date': date.today(), 'epochs': params['epochs'],
                                              'stride': params['stride_first_layer'],
                                              'dimension_reduction': params['dimension_reduction'],
                                              'learning_rate': params['learning_rate'], 'decay': params['weight_decay'],
                                              'depth': params['depth'], 'val_loss': test_losses,
                                              'ap_per_epoch': test_ap_list, 'ap_binary_per_epoch': binary_ap_list,
                                              'train_loss': train_losses, 'mode': mode, 'lr_type': lr_type,
                                              'lr_adaptive': lr_adaptive,
                                              'k': k_list,
                                              'model_name': model_name,
                                              "lr_list": lr_list,
                                              'max_roc': max_roc,
                                              'max_ap': max_ap,
                                              'max_f1': max_f1,
                                              'ap_f1': ap_f1,
                                              'acc_t': acc,
                                              'max_acc_t': max_acc,
                                              "max_binary_ap": max_binary_ap,
                                              'duration': duration, 'batch_size': params['batch_size']},
                                             ignore_index=True)
    else:
        expirement_df = expirement_df.append({'date': date.today(), 'epochs': params['epochs'],
                                              'stride': params['stride_first_layer'],
                                              'dimension_reduction': params['dimension_reduction'],
                                              'learning_rate': params['learning_rate'], 'decay': params['weight_decay'],
                                              'depth': params['depth'], 'val_loss': test_losses,
                                              'ap_per_epoch': test_ap_list, 'ap_binary_per_epoch': binary_ap_list,
                                              'train_loss': train_losses, 'mode': mode, 'lr_type': lr_type,
                                              'lr_adaptive': lr_adaptive,
                                              'k': k_list, 'channel_mask': net.channel_mask.cpu().tolist(),
                                              'model_name': model_name, 'top_channels_list': top_channels_list,
                                              'energy_list': energy_list,
                                              'mask_mean': mask_weights, "lr_list": lr_list, 'lammba_list': lambda_list,
                                              'duration': duration, 'batch_size': params['batch_size']},
                                             ignore_index=True)

    expirement_df.to_csv(results_path + "/experiments.csv", index=False)
    try:
        plot_train(train_losses, test_losses, str(len(expirement_df.index)) + '_In_train', test_ap_list, binary_ap_list,
                   is_print_ap_K)
        if is_print_ap_K == True and is_train == "normal":
            plot_ap_k(str(len(expirement_df.index)), energy_list, test_ap_list, binary_ap_list)
    except:
        print("Error in training plotting loss")
    print(f'\nDuration: {duration:.0f} seconds')  # print the time elapsed
    return train_losses, test_losses, len(expirement_df.index), net


def plot_train(train_losses, test_losses, train_idx, ap_list, ap_binary="", is_print_ap_K=False):
    if not is_print_ap_K:
        plt.plot(train_losses, label='training loss')
    plt.plot(test_losses, label='validation loss')
    plt.plot(ap_list, label='AP')
    if ap_binary != "":
        plt.plot(ap_binary, label='ap_binary')
    plt.title('Loss at the end of each epoch')
    plt.legend()
    plt.savefig(f'{results_path}/loss_fig_{train_idx}')
    plt.close()
    if is_print_ap_K:
        plt.plot(train_losses, label='training loss')
        plt.title('Train Loss at the end of each epoch')
        plt.legend()
        plt.savefig(f'{results_path}/Train_loss_fig_{train_idx}')
        plt.close()


def plot_ap_k(train_idx, k_list, ap_list, ap_binary):
    x = np.arange(0, len(k_list), 1)
    y1 = ap_list
    y2 = k_list
    y3 = ap_binary
    fig, ax1 = plt.subplots()
    ax2 = ax1.twinx()
    ax2.plot(x, y2, 'b-', label="energy")
    ax1.plot(x, y1, 'g-', label="ap")
    ax1.plot(x, y3, 'r-', label="binary_ap")
    ax1.set_xlabel('epochs')
    ax1.set_ylabel('ap', color='g')
    # ax1.set_ylabel('ap_binary', color='r')
    ax2.set_ylabel('k', color='b')
    plt.title('AP_K per epoch')
    ax1.legend(loc="upper left")
    ax2.legend(loc="upper right")
    plt.savefig(f'{results_path}/AP_K{train_idx}')
    plt.close()


# evaluating and loss
def cal_loss_mse(input, target):
    loss = torch.pow(input - target, 2)  # criterion(y_pred, torch.FloatTensor(y_train))
    loss = loss * params['loss_mask'].reshape((1, total_phenotypes))
    loss = torch.sum(loss)
    return loss


def cal_loss_BCE_old(input, target):
    BCELoss = nn.BCELoss()
    loss = BCELoss(input, target)
    return loss


def cal_loss_BCE(input, target, weight, batch_size):
    # choose weight according to label
    indices = target.data.view(-1).long()
    indices = indices.unsqueeze(-1)
    weight_ = torch.gather(weight, 1, indices)
    # #cal loss
    criterion = nn.BCELoss(reduce=False)
    loss = criterion(input, target)
    # # mask loss and multiple by weights
    # loss = loss * params['loss_mask'].reshape((1, params['loss_mask'].shape[0]))
    loss = torch.reshape(loss, (-1, 1)) * weight_
    loss = loss.reshape([batch_size, -1])
    # indices = torch.nonzero(params['loss_mask']).flatten()
    # loss = loss[:, indices]
    loss = loss.mean()
    return loss


def cal_loss_huber(input, target):
    huber_loss = nn.SmoothL1Loss(size_average=False, reduce=False, reduction='mean', beta=0.01)  # loss per element
    element_loss = huber_loss(input, target)
    loss = element_loss * params['loss_mask'].reshape((1, total_phenotypes))
    loss = torch.sum(loss) / (torch.count_nonzero(params['loss_mask']) * element_loss.shape[0])
    return loss


def cal_mae(input, target):
    element_loss = torch.abs(input - target)
    loss = element_loss * params['loss_mask'].reshape((1, total_phenotypes))
    loss = torch.sum(loss) / (torch.count_nonzero(params['loss_mask']) * element_loss.shape[0])
    element_loss = torch.mean(element_loss, axis=0)
    return loss, element_loss


def conf_matrix(input, target):
    labels_ranking = np.arange(1, label_rank + 1)
    cm = confusion_matrix(input, target, labels=labels_ranking)  # labels=labels
    # precision = precision_score(input, target, labels=labels_ranking, average='micro')
    # recall = recall_score(input, target, labels=labels_ranking, average='micro')
    return cm


def plot_confusion_matrics(input, target, title, labels_ranking, axs, index):
    cm = confusion_matrix(target.cpu(), input.cpu(), labels=labels_ranking)
    df_cm = pd.DataFrame(cm, range(label_rank), range(label_rank))
    # plt.figure(figsize=(10, 7))
    sn.set(font_scale=1.6)  # for label size
    sn.heatmap(df_cm, annot=True, ax=axs[index], annot_kws={"size": 28}).set_title(f"{title}")  # font size
    # plt.xlabel("Predicted")
    # plt.ylabel("Actual")
    # plt.show()
    # plt.clf()
    # print(f"confusion matrix {title}: \n{cm}")
    return cm, axs


def plot_recall_precision(y_test, y_scores, is_print, title="", axs="", index="", file_name=""):
    # print("create recall-precision plot")
    precision, recall, thresholds = precision_recall_curve(y_test.cpu(), y_scores.cpu())
    f1_scores = 2 * recall * precision / (recall + precision)
    #  print('Best threshold: ', thresholds[np.argmax(f1_scores)])
    max_f1 = np.max(f1_scores)
    print('Best F1-Score: ', max_f1)
    auc_res = auc(recall, precision)
    if is_print:
        axs[index].step(recall, precision, color='b', alpha=0.2, where='post')
        axs[index].fill_between(recall, precision, alpha=0.2, color='b')
        # axs[index].xlabel('Recall') fontsize=16
        # # axs[index].ylabel('Precision')
        # axs[index].ylim([0.0, 1.05])
        # axs[index].xlim([0.0, 1.0])
        axs[index].set_title(f'Precision-Recall curve {title}: AUC={round(auc_res, 3)}', fontsize=20)
    return auc_res, max_f1


def plot_confusion_matrics_old(input, target, title, labels_ranking):
    cm = confusion_matrix(target.cpu(), input.cpu(), labels=labels_ranking)
    df_cm = pd.DataFrame(cm, range(label_rank), range(label_rank))
    plt.figure(figsize=(10, 7))
    sn.set(font_scale=1.8)  # for label size
    fig = sn.heatmap(df_cm, annot=True, annot_kws={"size": 30}).set_title(f"confusion matrix {title}")  # font size
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    # plt.show()
    fig = fig.get_figure()
    fig.savefig(results_path + "/" + title + "_cm.png")
    plt.cla()
    plt.close()
    # print(f"confusion matrix {title}: \n{cm}")
    return cm


def plot_recall_precision_old(y_test, y_scores, title):
    # print("create recall-precision plot")
    precision, recall, thresholds = precision_recall_curve(y_test.cpu(), y_scores.cpu())
    # print(f'thresholds {title}: {thresholds}')
    auc_res = auc(recall, precision)
    plt.figure(figsize=(10, 7))
    plt.step(recall, precision, color='b', alpha=0.2, where='post')
    plt.fill_between(recall, precision, alpha=0.2, color='b')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.ylim([0.0, 1.05])
    plt.xlim([0.0, 1.0])
    plt.title(f'Precision-Recall curve {title}: AUC={round(auc_res, 3)}')
    # plt.show()
    plt.savefig(f"{results_path}/precision_recall_{title}.png")
    plt.close()
    pass


def str_to_list(list_str):
    list_str = list_str.replace('[', '')
    list_str = list_str.replace(']', '')
    my_list = list_str.split(",")
    return my_list


def plot_roc_curve(y_test, y_scores, title, is_train=False, max_roc=1):
    # generate a no skill prediction (majority class)
    ns_probs = [0 for _ in range(len(y_test))]
    # calculate scores
    ns_auc = roc_auc_score(y_test, ns_probs)
    model_auc = roc_auc_score(y_test, y_scores)
    # summarize scores
    print('No Skill: ROC AUC=%.3f' % (ns_auc))
    print('Logistic: ROC AUC=%.3f' % (model_auc))
    # calculate roc curves
    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
    model_fpr, lr_tpr, _ = roc_curve(y_test, y_scores)
    if is_train:
        max_roc = model_auc
        # plot the roc curve for the model
        plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
        plt.plot(model_fpr, lr_tpr, marker='.', label='model')
        # axis labels
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        # show the legend
        plt.legend()
        plt.title(f'roc_curve_{title}')
        # show the plot
        if max_roc < model_auc:
            plt.savefig(f"{results_path}/roc_1_max_AUC:{str(model_auc)}_{title}.png")
        else:
            plt.savefig(f"{results_path}/roc_1_AUC:{str(model_auc)}_{title}.png")
        plt.close()
    else:
        # plot the roc curve for the model
        plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
        plt.plot(model_fpr, lr_tpr, marker='.', label='model')
        # axis labels
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        # show the legend
        plt.legend()
        plt.title(f'roc_curve_{title}')
        # show the plot
        plt.savefig(f"{results_path}/roc_AUC:{str(model_auc)}_{title}.png")
        plt.close()
    return model_auc, max_roc


def valuate_model(test_loader_val, net, params):
    """
    valuates the test data on the model "net"
    """
    net.eval()
    # Run the testing batches
    test_running_loss = 0.0
    test_running_mae = 0.0
    total_predictions = []
    total_scores = []
    total_labels = []
    test_running_mae_element = torch.zeros(total_phenotypes).to(device)
    net.eval()
    with torch.no_grad():
        b_num_test = 0
        for b, (X_test, y_test) in enumerate(test_loader_val):
            b_num_test += 1
            y_pred = net(X_test.float())
            # mask phenotypes and adjust tensors by mode
            indices = torch.nonzero(params['loss_mask']).flatten()
            y_pred = y_pred[:, indices]
            if mode == "max_neuron":
                """add neuron of max for loss cal"""
                y_pred = set_last_neuron_max(y_pred, dim=1)
            elif mode == "eval_only_max_neuron":
                """net has last neuron, turn it to max"""
                y_pred = set_last_neuron_max(y_pred, params, dim=1)
            y_test = add_max_to_tensor(y_test, dim=1)
            y_test = y_test[:, indices]
            if model_type == "regression":
                test_loss = cal_loss_huber(y_pred, y_test.float())
                test_mae, element_mae = cal_mae(y_pred, y_test.float())
                prediction = torch.round(label_rank * y_pred)
                ground_truth = torch.round(label_rank * y_test)
                test_running_mae += test_mae
                test_running_mae_element += element_mae
            elif model_type == "binary":
                test_loss = cal_loss_BCE(y_pred, y_test.float(), params['weight_batch'], params['batch_size'])
                prediction = (y_pred > params['thresholds']).float()
                ground_truth = y_test

            test_running_loss += test_loss.item()
            total_predictions.append(prediction)
            total_scores.append(y_pred)
            total_labels.append(ground_truth)
            # test_maes_element.append(average_test_epoch_mae_element)
    net.train()
    average_test_loss = test_running_loss / b_num_test
    if model_type == "regression":
        average_test_mae = test_running_mae / b_num_test
        average_test_epoch_mae_element = test_running_mae_element / b_num_test
    # Unpack tensors from batches
    total_predictions = unpack_batches(total_predictions)
    total_scores = unpack_batches(total_scores)
    total_labels = unpack_batches(total_labels)

    # mask phenotypes
    # indices = torch.nonzero(params['y_testloss_mask']).flatten()# ap_phenotype = plot_recall_precision(total_labels[:, col].cpu(), total_scores[:, col].cpu(), labels_name_filtered[col] + "_prior=" + str(prior[col]), axs2, col, True)
    # total_predictions = total_predictions[:, indices]
    # total_scores = total_scores[:, indices]
    # total_labels = total_labels[:, indices]

    # total_scores = set_last_neuron_max(total_scores, params, dim=1)
    indices_numpy = indices.cpu()
    indices_numpy = indices_numpy.numpy()
    global labels
    global prior
    labels_name_filtered = np.array(labels)[indices_numpy.astype(int)]
    prior_filtered = np.array(prior)[indices_numpy.astype(int)]
    # per phenotype eval
    if model_type == "regression":
        labels_ranking = np.arange(1, label_rank + 1)
    elif model_type == "binary":
        labels_ranking = np.arange(0, label_rank)
    acc_per_phenotype = {}
    ap = {}
    f1 = {}
    # plot evaluations per phenotype
    # fig_rows = math.ceil(total_predictions.shape[1]/2)
    try:
        fig, axs = plt.subplots(total_predictions.shape[1], figsize=(24, 24))
        fig2, axs2 = plt.subplots(total_predictions.shape[1], figsize=(24, 24))
        # plt.figure(figsize=(10, 7))

        for col in range(total_predictions.shape[1]):
            # if params['loss_mask'][col] > 0:
            cm_per_phenotype, axs = plot_confusion_matrics(total_predictions[:, col], total_labels[:, col],
                                                           labels_name_filtered[col], labels_ranking, axs, col)
            acc_per_phenotype[labels_name_filtered[col]] = accuracy_score(total_predictions[:, col].cpu(),
                                                                          total_labels[:, col].cpu(), normalize=True)
            # ap_phenotype = plot_recall_precision(total_labels[:, col].cpu(), total_scores[:, col].cpu(), labels_name_filtered[col] + "_prior=" + str(prior[col]), axs2, col, True)
            ap[labels_name_filtered[col]], f1[labels_name_filtered[col]] = plot_recall_precision(
                total_labels[:, col].cpu(),
                total_scores[:, col].cpu(), True,
                labels_name_filtered[col] + "_prior=" + str(
                    prior_filtered[col]), axs2, col)

        average_ap = sum(ap.values()) / len(ap)

        for ax in axs2.flat:
            ax.set(xlabel='recall', ylabel='precision')
        # Hide x labels and tick labels for top plots and y ticks for right plots.
        for ax in axs2.flat:
            ax.label_outer()

        for ax in axs.flat:
            ax.set(xlabel='predicted', ylabel='actual')
        # Hide x labels and tick labels for top plots and y ticks for right plots.
        for ax in axs.flat:
            ax.label_outer()

        # fig = fig.get_figure()
        fig.savefig(results_path + "/" + "Confusion_Matrix" + model_name + ".png")
        plt.close()
        fig2.savefig(results_path + "/" + "Recall_Precision" + model_name + ".png")
        # plt.cla()
        plt.close()
        # over all eval
        roc_auc, _ = plot_roc_curve(total_labels[:, 2].cpu(), total_scores[:, 2].cpu(),
                                    labels_name_filtered[2] + "_" + model_name)
        # precision, recall, thresholds = precision_recall_curve(total_labels[:, 2].cpu(), total_scores[:, 2].cpu())
        # f1_scores = 2 * recall * precision / (recall + precision)
        #   print('Best threshold: ', thresholds[np.argmax(f1_scores)])
        # max_f1 = np.max(f1_scores)
        # print('Best F1-Score: ', max_f1)
        total_predictions = torch.flatten(total_predictions).cpu()
        total_scores = torch.flatten(total_scores).cpu()
        total_labels = torch.flatten(total_labels).cpu()
        cm = plot_confusion_matrics_old(total_predictions, total_labels, "All Phenotypes", labels_ranking)
        acc_total = accuracy_score(total_predictions, total_labels, normalize=True)
        plot_recall_precision_old(total_labels, total_scores, "All Predictions")
    except:
        print("Error in Plotting. Cant display")
        ##### had problems in plotting at run. usually after trainnig
        for col in range(total_predictions.shape[1]):
            # cm_per_phenotype, axs = plot_confusion_matrics(total_predictions[:, col], total_labels[:, col], labels_name_filtered[col], labels_ranking, axs, col)
            acc_per_phenotype[labels_name_filtered[col]] = accuracy_score(total_predictions[:, col].cpu(),
                                                                          total_labels[:, col].cpu(), normalize=True)
            # ap_phenotype = plot_recall_precision(total_labels[:, col].cpu(), total_scores[:, col].cpu(), labels_name_filtered[col] + "_prior=" + str(prior[col]), axs2, col, True)
            ap[labels_name_filtered[col]] = plot_recall_precision(total_labels[:, col].cpu(),
                                                                  total_scores[:, col].cpu(), False)
        average_ap = sum(ap.values()) / len(ap)
        acc_total = accuracy_score(total_predictions.cpu(), total_labels.cpu(), normalize=True)
    # save to file
    expirement_df = pd.read_csv(results_path + "/experiments.csv")
    if model_type == "regression":
        expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('val_mae')] = average_test_mae.cpu()
    elif model_type == "binary":
        expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('acc_total')] = acc_total
        expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('acc_per_phenotype')] = [acc_per_phenotype]
        expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('ap_phenotype')] = [ap]
        expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('average_ap')] = average_ap
        expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('roc_auc')] = roc_auc
        expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('f1')] = [f1]
        # plot train
        train_losses = expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('train_loss')]
        test_losses = expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('val_loss')]
        ap_per_epoch = expirement_df.iloc[experiments_index, expirement_df.columns.get_loc('ap_per_epoch')]
        train_losses = str_to_list(train_losses)
        test_losses = str_to_list(test_losses)
        ap_per_epoch = str_to_list(ap_per_epoch)
        train_losses = [float(i) for i in train_losses]
        test_losses = [float(i) for i in test_losses]
        ap_per_epoch = [float(i) for i in ap_per_epoch]
        try:
            plot_train(train_losses, test_losses, len(expirement_df.index), ap_per_epoch)
        except:
            print("Error printing loss plot")

    expirement_df.to_csv(results_path + "/experiments.csv", index=False)

    # print a report
    print(f"""
    average test loss: {average_test_loss:10.8f}
    classifaction report:
    {classification_report(total_labels.cpu(), total_predictions.cpu(), target_names=labels_ranking.astype('str'), labels=labels_ranking.astype('float64'))}
    """)

    return average_test_loss, average_ap


# Hyper parameter tuning


class Objective(object):
    def __init__(self, data_path, tuning_params, params, train_loader, val_loader, input_channel, n_classes):
        # Hold this implementation specific arguments as the fields of the class.
        self.data_path = data_path
        self.tuning_params = tuning_params
        self.params = params
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.input_channel = input_channel
        self.n_classes = n_classes

    def __call__(self, trial):
        print("tunning params...")
        """define hyperParams possible values"""
        lr = trial.suggest_float("lr", self.tuning_params['lr_low'],
                                 self.tuning_params['lr_high'],
                                 log=True)
        weight_decay = trial.suggest_float("weight_decay", self.tuning_params['decay_low'],
                                           self.tuning_params['decay_high'],
                                           log=True)
        """set the params"""
        print(
            f'params for study: lr= {lr}, dimension_span={weight_decay}')
        self.params['weight_decay'] = weight_decay
        # self.params['stride_first_layer'] = stride_first_layer
        self.params['learning_rate'] = lr
        """fit model"""
        # init model
        net, optimizer = init_model(self.params, self.input_channel, self.n_classes)

        # train
        running_losses, val_running_losses = train_model(self.train_loader, self.val_loader,
                                                         self.params,
                                                         optimizer, net)
        val_running_loss_last_epoch = val_running_losses[params['epochs'] - 1]
        return val_running_loss_last_epoch


def grid_search(tuning_params, params, train_loader, val_loader, input_channel, n_classes):
    # total_params = len(tuning_params['grid_search_params'])
    """
    preforms grid search on hyper parameters defined in tuning_params['grid_search_params'].
    builds model for every combination of values
    """
    print("start grid search hyperparameter")
    param_values = []
    columns = []
    for count, param in enumerate(tuning_params['grid_search_params']):
        param_values.append(tuning_params[param])
        columns.append(param)
    columns.append('val_loss')
    df = pd.DataFrame(columns=columns)
    for param_vals_1 in param_values[0]:
        for param_vals_2 in param_values[1]:
            params[tuning_params['grid_search_params'][0]] = param_vals_1
            params[tuning_params['grid_search_params'][1]] = param_vals_2
            print(
                f"building model :  {tuning_params['grid_search_params'][0]}=param_vals_1,   {tuning_params['grid_search_params'][1]}=param_vals_2 ")
            # init model
            net, optimizer = init_model(params, input_channel, n_classes)
            running_losses, val_running_losses = train_model(train_loader, val_loader,
                                                             params,
                                                             optimizer, net)
            val_running_loss_last_epoch = val_running_losses[params['epochs'] - 1]
            df.loc[len(df)] = [param_vals_1, param_vals_2, val_running_loss_last_epoch]
    df.to_csv(results_path + "/grid_search_" + '_'.join(tuning_params['grid_search_params']) + ".csv")
    plot_3d(df=df)
    pass


def visualize_study_set_best_params(study, params, tuning_params):
    """
    plots statistics of the optuna study.
    """
    print("visualizing study...")
    """set best params"""
    params['learning_rate'] = study.best_params['lr']
    params['weight_decay'] = study.best_params['weight_decay']
    df_trials = study.trials_dataframe()
    df_trials.to_csv(
        results_path + "/study_df_" + str(params["learning_rate"]) + "_" + params["weight_decay"] + ".csv")
    """optimzation_history"""
    plot = optuna.visualization.matplotlib.plot_optimization_history(study)
    # plot.show()
    fig = plot.get_figure()
    fig.savefig(results_path + "/optimazation_history.png")
    plot = optuna.visualization.matplotlib.plot_parallel_coordinate(study, tuning_params["visualizing_params"])
    # plot.show()
    fig = plot.get_figure()
    fig.savefig(results_path + "/parralel_coordinate.png")
    # plot_3d(df_trials)
    print("finished visualizing study")
    return params


def plot_3d(df=None):
    """
    :param df: 3d data frame
    plots a 3d plot of df
    """
    if df is None:
        df_study = pd.read_csv(results_path + '\\grid_search_dimension_reduction_stride_first_layer.csv')
    else:
        df_study = df
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    # For each set of style and range settings, plot n random points in the box
    # defined by x in [23, 32], y in [0, 100], z in [zlow, zhigh].
    for m in ['o', '^']:
        xs = df_study.iloc[:, 0]  # df_study['params_decay_rates']
        ys = df_study.iloc[:, 1]  # df_study['params_dropout_rates']
        zs = df_study.iloc[:, 2]  # df_study['value']
        ax.scatter(xs, ys, zs, marker=m)
    ax.set_xlabel(df_study.columns[0])
    ax.set_ylabel(df_study.columns[1])
    ax.set_zlabel(df_study.columns[2])
    plt.show()
    fig.savefig(results_path + "/3d_tuning.png")


def gpu_checks():
    print(f"is Cuda running: {torch.cuda.is_available()}")
    global resized_path
    global resized_img_path
    global labels_df
    global results_path
    global model_path
    if is_volcani:
        result_path = ""
    else:
        result_path = storage_path + "/ExpResults/tal_exp_results/"
    if torch.cuda.is_available():
        GPUtil.showUtilization()
        torch.multiprocessing.set_start_method('spawn')
        ## Get Id of default device
        gpu_id = torch.cuda.current_device()
        device = torch.device(f"cuda:{gpu_id}")
        device_name = torch.cuda.get_device_name(gpu_id)
        print(f"""
        the gpu device used: {device_name}
        memory allocated: {torch.cuda.memory_allocated()}
        memory cached: {torch.cuda.memory_cached()}
        """)
    else:
        device = torch.device("cpu")
    results_path = result_path + "results"
    model_path = results_path + "/" + model_name
    labels_df = pd.read_csv(f"{results_path}/phenotyping_with_groups_3.csv")  # phenotyping_with_groups_sparse.csv
    resized_path = result_path + hdr_folder_name
    resized_img_path = result_path + img_folder_name
    return device


if __name__ == '__main__':
    # prepare
    seed_everything(seed)
    device = gpu_checks()
    params = get_params(device)
    if only_resize:
        resize_and_save(params)
    else:
        df_train, df_val, df_test = get_data(data_path, resized_path)
        train_loader, test_loader, val_loader = load_data(df_train, df_val, df_test, params, device)
        input_channel = 730  # todo: make from shape
        # n_classes = df_train["label"][0].shape[0]

        if params['tuning_mode']:
            tuning_params = get_tuning_params()
            study = optuna.create_study()
            study.optimize(
                Objective(data_path, tuning_params, params, train_loader, val_loader, input_channel, total_phenotypes),
                n_trials=tuning_params['trials'])
            print(f'finished tunning params. best params = {study.best_params} with loss: {study.best_value}')
            params = visualize_study_set_best_params(study, params, tuning_params)
        elif params['grid_search_mode']:
            tuning_params = get_tuning_params()
            grid_search(tuning_params, params, train_loader, val_loader, input_channel, total_phenotypes)

        if is_train == "normal":
            # if is_channel_mean:
            #     cal_plot_mean_std_images()
            # init model
            net, optimizer = init_model(params, input_channel, total_phenotypes, device)
            # print(net.conv1.weight)
            # train
            train_losses, test_losses, index, net = train_model(train_loader, val_loader, params, optimizer, net)
            # print(net.conv1.weight)
            # valuate
            average_test_loss = valuate_model(val_loader, net, params)
            # print(net.conv1.weight)model
            # # save model
            # torch.save(net.state_dict(), 'ResNetModel.pt')
        elif is_train == "continue":
            # init model
            net, optimizer = init_model(params, input_channel, total_phenotypes, device)
            global model_path
            net.load_state_dict(torch.load(model_path + ".pt"))
            net.to(device)
            # turn off channels and freeze mask tensor
            k, not_k_indicies = get_k_value(energy_value, values=net.channel_mask.cpu().detach().numpy())
            print(f"The Final channel mask tensor before continue mode: {net.channel_mask}")
            net.channel_mask.requires_grad = False
            if channel_mask_mode == "L1":
                net.channel_mask[0, not_k_indicies.reshape((not_k_indicies.shape[1],))] = 0.
            elif channel_mask_mode == "softmax":
                net.channel_mask[0, not_k_indicies.reshape((not_k_indicies.shape[1],))] = -math.inf
            channel_mask_mode = ""
            # train
            train_losses, test_losses, index, net = train_model(train_loader, val_loader, params, optimizer, net)
            # valuate
            average_test_loss = valuate_model(val_loader, net, params)
        elif is_train == "continue_reset":
            channel_mask_mode = "L1"
            if not (channel_mask_mode == "random_channels"):
                # init model
                net, optimizer = init_model(params, input_channel, total_phenotypes, device)
                # global model_path
                net.load_state_dict(torch.load(model_path + ".pt"))
                net.to(device)
                print(f"The Final channel mask tensor before continue mode: {net.channel_mask}")
                net.channel_mask.requires_grad = False
            if channel_mask_mode == "L1":
                _, _, indices_1 = get_top_channels(net.channel_mask, top_num)
                # indices_1 = (net.channel_mask >= threshold) | (net.channel_mask <= -threshold)
                # indices_0 = net.channel_mask >= threshold
                # net.channel_mask[0, net.channel_mask < threshold] = 0.
                # net.channel_mask[0, net.channel_mask >= threshold] = 1.
            elif channel_mask_mode == "softmax":
                net.channel_mask[0, net.channel_mask < threshold] = -math.inf
                net.channel_mask[0, net.channel_mask >= threshold] = -math.inf
            elif channel_mask_mode == "random_channels":
                indices_1 = torch.arange(0, 730, 73)
                indices_1 = torch.reshape(indices_1, (1, -1))
            elif channel_mask_mode == "all_channels":
                indices_1 = torch.ones(730)
                indices_1 = torch.reshape(indices_1, (1, -1))
            indices_list = indices_1.tolist()
            print(f"the channels in model for top {top_num} channels are {Wavelength[indices_list]}")
            input_channel_sparse = torch.numel(indices_1)
            train_loader_sparse, test_loader_sparse, val_loader_sparse = load_data(df_train, df_val, df_test, params,
                                                                                   device, is_sparse=True,
                                                                                   indices=indices_1)
            channel_mask_mode = "none"
            sparse_params = get_sparse_model_params()
            net_new, optimizer = init_model(sparse_params, input_channel_sparse, total_phenotypes, device)
            # net_new.channel_mask = net.channel_mask
            # net.channel_mask.requires_grad = False
            # train
            train_losses, test_losses, index, net_new = train_model(train_loader_sparse, val_loader_sparse, params, optimizer,
                                                           net_new)
            # valuate
            average_test_loss = valuate_model(val_loader_sparse, net_new, params)

        elif is_train == "eval":
            net = ResNet(input_channel, params["dimension_reduction"], params["stride_first_layer"],
                         params["dimension_span"], total_phenotypes, device)
            # global model_path
            net.load_state_dict(torch.load(model_path + ".pt"))
            net.to(device)
            average_test_loss, average_ap = valuate_model(val_loader, net, params)

######## data #########################
